{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170146db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import  train_test_split\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70e9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('crude oil dataset/MAIN - Copy.xlsx')\n",
    "df = data\n",
    "data.head()\n",
    "df = df.drop(['Date'], axis='columns')\n",
    "df.columns = range(df.shape[1])   \n",
    "target = np.array(df[0])\n",
    "df = df.drop([0],axis='columns')\n",
    "#df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbd8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.astype('float32')\n",
    "y = target.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67019e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:24]\n",
    "y_train = y[0:24]\n",
    "X_val = X[24:32]\n",
    "y_val = y[24:32]\n",
    "X_test = X[32:40]\n",
    "y_test = y[32:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba906611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "Xs_train = scaler.transform(X_train)\n",
    "Xs_test = scaler.transform(X_test)\n",
    "Xs_val = scaler.transform(X_val)\n",
    "#print(Xs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "#tf.keras.layers.Dense(5, activation='relu'), \n",
    "tf.keras.layers.Dense(3, activation='relu',input_dim=2),\n",
    "#tf.keras.layers.Dense(8, activation='relu'),\n",
    "#tf.keras.layers.Dense(4, activation='relu'),\n",
    "#tf.keras.layers.Dropout(.1),\n",
    "tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb87c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305ff00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 2s 2s/step - loss: 57.9263 - val_loss: 57.5663\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.9213 - val_loss: 57.5613\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.9162 - val_loss: 57.5563\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.9113 - val_loss: 57.5513\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.9062 - val_loss: 57.5462\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.9012 - val_loss: 57.5413\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.8963 - val_loss: 57.5363\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8913 - val_loss: 57.5312\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.8862 - val_loss: 57.5263\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.8813 - val_loss: 57.5213\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.8763 - val_loss: 57.5163\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8712 - val_loss: 57.5113\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8663 - val_loss: 57.5063\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8613 - val_loss: 57.5013\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 57.8563 - val_loss: 57.4963\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 57.8513 - val_loss: 57.4913\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 57.8462 - val_loss: 57.4863\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 57.8413 - val_loss: 57.4813\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 57.8363 - val_loss: 57.4762\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8313 - val_loss: 57.4713\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.8263 - val_loss: 57.4663\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8212 - val_loss: 57.4613\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.8163 - val_loss: 57.4563\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 57.8112 - val_loss: 57.4513\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 57.8062 - val_loss: 57.4463\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.8013 - val_loss: 57.4413\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.7962 - val_loss: 57.4363\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 57.7912 - val_loss: 57.4313\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 57.7863 - val_loss: 57.4263\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 57.7812 - val_loss: 57.4212\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.7762 - val_loss: 57.4163\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.7713 - val_loss: 57.4113\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.7663 - val_loss: 57.4062\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.7612 - val_loss: 57.4013\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 57.7563 - val_loss: 57.3963\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 57.7513 - val_loss: 57.3913\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.7463 - val_loss: 57.3863\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.7413 - val_loss: 57.3813\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.7363 - val_loss: 57.3763\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.7313 - val_loss: 57.3713\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.7263 - val_loss: 57.3663\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.7213 - val_loss: 57.3613\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.7163 - val_loss: 57.3563\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.7113 - val_loss: 57.3512\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.7062 - val_loss: 57.3463\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.7013 - val_loss: 57.3413\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6962 - val_loss: 57.3363\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6912 - val_loss: 57.3313\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.6862 - val_loss: 57.3263\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6813 - val_loss: 57.3213\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6763 - val_loss: 57.3163\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6712 - val_loss: 57.3113\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6662 - val_loss: 57.3063\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6613 - val_loss: 57.3013\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.6562 - val_loss: 57.2962\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.6512 - val_loss: 57.2913\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6463 - val_loss: 57.2863\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.6413 - val_loss: 57.2812\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6362 - val_loss: 57.2763\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 57.6313 - val_loss: 57.2713\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.6263 - val_loss: 57.2663\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.6213 - val_loss: 57.2613\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6163 - val_loss: 57.2563\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6113 - val_loss: 57.2513\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.6063 - val_loss: 57.2463\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.6012 - val_loss: 57.2413\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5963 - val_loss: 57.2363\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5912 - val_loss: 57.2313\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5863 - val_loss: 57.2262\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5812 - val_loss: 57.2213\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.5763 - val_loss: 57.2163\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5712 - val_loss: 57.2113\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.5663 - val_loss: 57.2063\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5612 - val_loss: 57.2013\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5563 - val_loss: 57.1963\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.5513 - val_loss: 57.1913\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5462 - val_loss: 57.1863\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5412 - val_loss: 57.1813\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.5363 - val_loss: 57.1763\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5312 - val_loss: 57.1713\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5263 - val_loss: 57.1663\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5213 - val_loss: 57.1613\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.5163 - val_loss: 57.1562\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.5112 - val_loss: 57.1513\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5063 - val_loss: 57.1463\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.5013 - val_loss: 57.1413\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.4963 - val_loss: 57.1363\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.4913 - val_loss: 57.1313\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4863 - val_loss: 57.1263\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4813 - val_loss: 57.1213\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4762 - val_loss: 57.1163\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4712 - val_loss: 57.1113\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4663 - val_loss: 57.1063\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4613 - val_loss: 57.1012\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 57.4563 - val_loss: 57.0963\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4513 - val_loss: 57.0913\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4463 - val_loss: 57.0863\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4413 - val_loss: 57.0813\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4363 - val_loss: 57.0763\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4313 - val_loss: 57.0713\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4263 - val_loss: 57.0663\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.4212 - val_loss: 57.0613\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4162 - val_loss: 57.0563\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.4113 - val_loss: 57.0513\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.4062 - val_loss: 57.0463\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 57.4013 - val_loss: 57.0413\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.3963 - val_loss: 57.0363\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.3913 - val_loss: 57.0312\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3862 - val_loss: 57.0263\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3813 - val_loss: 57.0213\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3763 - val_loss: 57.0163\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3713 - val_loss: 57.0113\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3663 - val_loss: 57.0063\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3613 - val_loss: 57.0013\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3563 - val_loss: 56.9963\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.3512 - val_loss: 56.9913\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.3463 - val_loss: 56.9863\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3412 - val_loss: 56.9813\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3363 - val_loss: 56.9762\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3312 - val_loss: 56.9713\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3263 - val_loss: 56.9663\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3212 - val_loss: 56.9613\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3162 - val_loss: 56.9563\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.3112 - val_loss: 56.9513\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.3062 - val_loss: 56.9463\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.3013 - val_loss: 56.9413\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2963 - val_loss: 56.9363\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2912 - val_loss: 56.9313\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2863 - val_loss: 56.9263\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2812 - val_loss: 56.9213\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.2762 - val_loss: 56.9163\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2713 - val_loss: 56.9113\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2663 - val_loss: 56.9062\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2612 - val_loss: 56.9013\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.2563 - val_loss: 56.8963\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2512 - val_loss: 56.8913\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.2463 - val_loss: 56.8863\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2413 - val_loss: 56.8813\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2363 - val_loss: 56.8763\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.2313 - val_loss: 56.8713\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2263 - val_loss: 56.8663\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.2213 - val_loss: 56.8613\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2163 - val_loss: 56.8563\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2113 - val_loss: 56.8513\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.2063 - val_loss: 56.8463\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.2013 - val_loss: 56.8413\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1963 - val_loss: 56.8363\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.1913 - val_loss: 56.8313\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1862 - val_loss: 56.8263\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1813 - val_loss: 56.8213\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1763 - val_loss: 56.8163\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1713 - val_loss: 56.8113\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1663 - val_loss: 56.8063\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1613 - val_loss: 56.8013\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1562 - val_loss: 56.7963\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.1512 - val_loss: 56.7913\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1463 - val_loss: 56.7863\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1412 - val_loss: 56.7812\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1362 - val_loss: 56.7763\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1313 - val_loss: 56.7713\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1263 - val_loss: 56.7663\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1213 - val_loss: 56.7613\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1163 - val_loss: 56.7563\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1112 - val_loss: 56.7513\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.1063 - val_loss: 56.7463\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.1012 - val_loss: 56.7413\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0963 - val_loss: 56.7363\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0912 - val_loss: 56.7313\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.0863 - val_loss: 56.7263\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0813 - val_loss: 56.7213\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.0763 - val_loss: 56.7163\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0712 - val_loss: 56.7113\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.0662 - val_loss: 56.7063\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 57.0612 - val_loss: 56.7013\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0563 - val_loss: 56.6963\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 57.0513 - val_loss: 56.6913\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.0463 - val_loss: 56.6863\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0412 - val_loss: 56.6813\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0363 - val_loss: 56.6763\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.0312 - val_loss: 56.6713\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 57.0262 - val_loss: 56.6663\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 57.0213 - val_loss: 56.6613\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0163 - val_loss: 56.6562\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0112 - val_loss: 56.6513\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0063 - val_loss: 56.6463\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 57.0013 - val_loss: 56.6413\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.9962 - val_loss: 56.6363\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9913 - val_loss: 56.6313\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9863 - val_loss: 56.6263\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.9813 - val_loss: 56.6213\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9763 - val_loss: 56.6163\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9713 - val_loss: 56.6113\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9663 - val_loss: 56.6063\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.9613 - val_loss: 56.6013\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.9563 - val_loss: 56.5963\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 56.9513 - val_loss: 56.5913\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9463 - val_loss: 56.5863\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 56.9413 - val_loss: 56.5813\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.9362 - val_loss: 56.5763\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 56.9312 - val_loss: 56.5713\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_val,y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba2c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE:43.938, MAE:41.200\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test).flatten()\n",
    "diff = predictions.flatten() - y_test\n",
    "percentDiff = (diff / y_test) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "mean = np.mean(absPercentDiff)\n",
    "\n",
    "rmse, mae, score = np.sqrt(mean_squared_error(y_test, predictions)), \\\n",
    "                   mean_absolute_error(y_test, predictions), r2_score(y_test, predictions)\n",
    "print(\" RMSE:%5.3f, MAE:%5.3f\" %(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6528491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.03 59.88 57.52 50.54 29.21 16.55 28.56 38.31] \n",
      " [0.999999 0.999999 0.999999 0.999999 0.999999 0.999999 0.999999 0.999999]\n"
     ]
    }
   ],
   "source": [
    "print(y_test,\"\\n\",predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
