{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364f561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "range(0, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('crude oil dataset/MAIN - Copy.xlsx')\n",
    "\n",
    "df = data\n",
    "data.head()\n",
    "df = df.drop(['Date'], axis='columns')\n",
    "print (df.shape[1])          # Show dimension of thecolumns\n",
    "print (range(df.shape[1]) )  # Show range of the columns\n",
    "\n",
    "df.columns = range(df.shape[1])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1ce1060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21008.65       19328.20427255 18006.87409377  9184.\n",
      "   2031.449       4865.959     ]\n",
      " [21349.63       19442.69225942 18091.68838159  9110.\n",
      "   2007.26        5076.598     ]\n",
      " [21891.12       19441.87258848 18062.58191921  9246.\n",
      "   1995.639       5095.003     ]\n",
      " [21948.1        19528.112628   18110.19625887  9245.\n",
      "   1983.689       4831.991     ]\n",
      " [22405.09       19706.09378347 18206.25594975  9516.\n",
      "   1974.589       4815.699     ]\n",
      " [23377.24       19742.23477231 18187.68975595  9659.\n",
      "   1938.591       4873.293     ]\n",
      " [24272.35       19911.77065808 18330.35559935 10077.\n",
      "   1920.612       5135.217     ]\n",
      " [24719.22       19994.88956959 18372.46260143  9979.\n",
      "   1892.001       4802.383     ]\n",
      " [26149.39       20048.25473424 18389.78339708  9996.\n",
      "   1879.441       5207.762     ]\n",
      " [25029.2        20191.73886818 18487.27321037 10276.\n",
      "   1875.453       4862.815     ]\n",
      " [24103.11       20191.15439756 18432.15554999 10461.\n",
      "   1861.294       5186.903     ]\n",
      " [24163.15       20385.66695984 18538.72924962 10493.\n",
      "   1864.851       4750.44      ]\n",
      " [24415.84       20511.22106513 18599.74214313 10424.\n",
      "   1870.105       5018.158     ]\n",
      " [24271.41       20580.58797495 18632.02815847 10628.\n",
      "   1866.842       5177.94      ]\n",
      " [25415.19       20591.13655675 18625.38319558 10888.\n",
      "   1872.599       5258.173     ]\n",
      " [25964.82       20689.40624761 18723.43358294 11373.\n",
      "   1891.869       5682.011     ]\n",
      " [26458.31       20696.76319566 18690.59396042 11422.\n",
      "   1931.197       5259.146     ]\n",
      " [25115.76       20814.72174204 18731.25784557 11488.\n",
      "   1915.062       5506.956     ]\n",
      " [25538.46       20787.4505261  18679.35229297 11868.\n",
      "   1907.339       5120.05      ]\n",
      " [23327.46       20837.80273189 18753.92758392 11924.\n",
      "   1908.077       4750.435     ]\n",
      " [24999.67       20972.96536194 18831.76646148 11848.\n",
      "   1914.152       5386.811     ]\n",
      " [25916.         20985.50767637 18827.33511802 11653.\n",
      "   1897.44        4856.632     ]\n",
      " [25928.68       21046.29996173 18841.18467513 11899.\n",
      "   1894.336       4812.474     ]\n",
      " [26592.91       21205.18936687 18914.47215639 12125.\n",
      "   1912.22        5041.197     ]\n",
      " [24815.04       21279.51779086 18969.11508784 12141.\n",
      "   1951.942       5101.905     ]\n",
      " [26599.96       21383.09684236 19064.69132596 12179.\n",
      "   1948.984       5134.581     ]\n",
      " [26864.27       21461.82848384 19082.49216822 11896.\n",
      "   1953.893       5337.118     ]\n",
      " [26403.28       21502.02222798 19105.22354336 12475.\n",
      "   1945.503       5372.51      ]\n",
      " [26916.83       21551.18528818 19150.8820847  12572.\n",
      "   1943.205       5450.935     ]\n",
      " [27046.23       21623.91199414 19143.85372662 12771.\n",
      "   1926.722       5435.91      ]\n",
      " [28051.41       21717.30212399 19234.6965566  12966.\n",
      "   1918.205       5297.732     ]\n",
      " [28538.44       21742.15988186 19228.96492263 12910.\n",
      "   1916.847       5072.86      ]\n",
      " [28256.03       21781.52354093 19213.05385628 12852.\n",
      "   1934.86        5219.143     ]\n",
      " [25409.36       21902.75371618 19345.15297421 12842.\n",
      "   1917.68        5240.934     ]\n",
      " [21917.16       20759.82374303 18298.82543558 12797.\n",
      "   1961.689       5317.735     ]\n",
      " [24345.72       18508.7898367  16436.13132638 11914.\n",
      "   2041.425       4205.671     ]\n",
      " [25383.11       19366.25541595 17179.8284924   9713.\n",
      "   2080.564       4670.506     ]\n",
      " [25812.88       20557.28674728 18164.2942525  10442.\n",
      "   2113.726       4865.208     ]\n",
      " [26428.32       20851.52043693 18326.72655547 11006.\n",
      "   2110.128       5189.11      ]\n",
      " [28430.05       21138.83232862 18570.20629984 10577.\n",
      "   2085.108       5277.888     ]\n",
      " [27781.7        21425.36923446 18792.95593524 10921.\n",
      "   2065.367       5144.516     ]\n",
      " [26501.6        21619.37462762 18924.25669964 10457.\n",
      "   2024.885       5285.616     ]\n",
      " [29638.64       21379.73093644 18703.24086817 11196.\n",
      "   2026.809       5576.809     ]\n",
      " [30606.48       21433.68543589 18683.44413533 11168.\n",
      "   1981.434       5462.344     ]\n",
      " [29982.62       22000.41791708 19093.30005769 11124.\n",
      "   1968.148       5306.722     ]\n",
      " [30932.37       21705.10633514 18790.46423284  9925.\n",
      "   1932.524       3824.643     ]\n",
      " [32981.55       22409.1537478  19291.48717729 11326.\n",
      "   1939.502       5038.032     ]\n",
      " [33874.85       22590.37198354 19334.79143023 11305.\n",
      "   1922.781       5272.245     ]\n",
      " [34529.45       22725.8907312  19363.28193426 11356.\n",
      "   1921.276       5591.16      ]\n",
      " [34502.51       22906.61428528 19415.22120629 11356.\n",
      "   1892.803       5781.077     ]\n",
      " [34935.47       22947.72842864 19344.6914251  11347.\n",
      "   1890.189       5185.669     ]\n",
      " [35360.73       23256.8607004  19525.33077108 11277.\n",
      "   1862.558       5778.053     ]\n",
      " [33843.92       23402.44287089 19575.2407289  10918.\n",
      "   1858.475       5718.316     ]\n",
      " [35819.56       23921.10147127 19850.52823488 11569.\n",
      "   1858.006       5246.998     ]\n",
      " [34483.72       23977.05570733 19782.46096968 11790.\n",
      "   1830.153       5448.717     ]\n",
      " [36338.3        24110.28782135 19794.74383683 11634.\n",
      "   1787.511       5642.666     ]\n",
      " [35131.86       24208.61058323 19737.18812525 11369.\n",
      "   1778.304       5478.438     ]\n",
      " [33892.6        24376.95683164 19738.82118819 11306.\n",
      "   1744.322       5478.424     ]\n",
      " [34678.35       24575.07312102 19716.9573344  11701.\n",
      "   1719.69        5438.934     ]\n",
      " [32977.21       24647.56580657 19672.47988434 11652.\n",
      "   1701.365       5373.042     ]]\n"
     ]
    }
   ],
   "source": [
    "#target = np.array(df[0])\n",
    "#df = df.drop([0],axis='columns')\n",
    "num_data = np.array(df)\n",
    "target = target.reshape(-1,1)\n",
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4364c729",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 6 and 5 for '{{node First_Layer/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholders/Placeholder, First_Layer/MatMul/ReadVariableOp)' with input shapes: [?,6], [5,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m     b_fc1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mget_variable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst_Layer/Biases\u001b[39m\u001b[38;5;124m'\u001b[39m, initializer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconstant(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m#<tf.Variable 'First_Layer/Variable_1:0' shape=(3,) dtype=float32_ref>\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     h_fc1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_fc1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b_fc1)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m#<tf.Tensor 'First_Layer/Relu:0' shape=(?, 3) dtype=float32>\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput_Layer\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2013\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   2010\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2012\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 2013\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 6 and 5 for '{{node First_Layer/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholders/Placeholder, First_Layer/MatMul/ReadVariableOp)' with input shapes: [?,6], [5,3]."
     ]
    }
   ],
   "source": [
    "#Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "def get_trainable_variables(graph=tf.compat.v1.get_default_graph()):\n",
    "    return [v for v in graph.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES)]\n",
    "\n",
    "def miniBatch(x, y, batchSize):\n",
    "    numObs  = x.shape[0]\n",
    "    batches = [] \n",
    "    batchNum = math.floor(numObs / batchSize)\n",
    "    \n",
    "    if numObs % batchSize == 0:\n",
    "        for i in range(batchNum):\n",
    "            xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "            yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "            batches.append((xBatch, yBatch))\n",
    "    else:\n",
    "        for i in range(batchNum):\n",
    "            xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "            yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "            batches.append((xBatch, yBatch))\n",
    "        xBatch = x[batchNum * batchSize:, :]\n",
    "        yBatch = y[batchNum * batchSize:, :]\n",
    "        batches.append((xBatch, yBatch))\n",
    "    return batches\n",
    "\n",
    "data = num_data\n",
    "#(4, 5)\n",
    "\n",
    "n_features = data.shape[1]\n",
    "n_outputs = target.shape[1]\n",
    "n_hidden = 3\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('Placeholders'):\n",
    "        X = tf.compat.v1.placeholder('float', shape=[None, n_features])\n",
    "        #<tf.Tensor 'Placeholder:0' shape=(?, 5) dtype=float32>\n",
    "        y = tf.compat.v1.placeholder('float', shape=[None, n_outputs])\n",
    "        #<tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>\n",
    "\n",
    "    with tf.name_scope(\"First_Layer\"):\n",
    "        W_fc1 = tf.compat.v1.get_variable('First_Layer/Hidden_layer_weights', initializer=tf.constant(np.array([[0.19, 0.55, 0.76],[0.33, 0.16, 0.97],[0.4 , 0.35, 0.7 ],[0.51, 0.85, 0.85],[0.54, 0.49, 0.57]]), dtype=tf.float32))\n",
    "        #<tf.Variable 'First_Layer/Variable:0' shape=(5, 3) dtype=float32_ref>\n",
    "        b_fc1 = tf.compat.v1.get_variable('First_Layer/Biases', initializer=tf.constant(np.array([0.1, 0.1, 0.1]), dtype=tf.float32))\n",
    "        #<tf.Variable 'First_Layer/Variable_1:0' shape=(3,) dtype=float32_ref>\n",
    "        h_fc1 = tf.compat.v1.nn.sigmoid(tf.matmul(X, W_fc1) + b_fc1)\n",
    "        #<tf.Tensor 'First_Layer/Relu:0' shape=(?, 3) dtype=float32>\n",
    "\n",
    "    with tf.name_scope(\"Output_Layer\"):\n",
    "        W_fc2 = tf.compat.v1.get_variable('Output_Layer/Output_layer_weights', initializer=tf.constant(np.array([[ 0.10],[ 0.03],[-0.17]]), dtype=tf.float32))\n",
    "        # <tf.Variable 'Output_Layer/Variable:0' shape=(3, 1) dtype=float32_ref>\n",
    "        b_fc2 = tf.compat.v1.get_variable('Output_Layer/Biases', initializer=tf.constant(np.array([0.1]), dtype=tf.float32))\n",
    "        # <tf.Variable 'Output_Layer/Variable_1:0' shape=(1,) dtype=float32_ref>\n",
    "        y_pred = tf.compat.v1.cast(tf.matmul(h_fc1, W_fc2) + b_fc2, dtype = tf.float32)\n",
    "        #<tf.Tensor 'Output_Layer/add:0' shape=(?, 1) dtype=float32>\n",
    "\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        loss = tf.compat.v1.losses.mean_squared_error(labels = y, predictions = y_pred)\n",
    "\n",
    "    with tf.name_scope('Train'):\n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.5)\n",
    "        grads_and_vars = optimizer.compute_gradients(loss)\n",
    "        trainer = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "    # [(<tf.Tensor 'Train/gradients/First_Layer/MatMul_grad/tuple/control_dependency_1:0' shape=(5, 3) dtype=float32>,\n",
    "    #   <tf.Variable 'First_Layer/Variable:0' shape=(5, 3) dtype=float32_ref>),\n",
    "    #  (<tf.Tensor 'Train/gradients/First_Layer/add_grad/tuple/control_dependency_1:0' shape=(3,) dtype=float32>,\n",
    "    #   <tf.Variable 'First_Layer/Variable_1:0' shape=(3,) dtype=float32_ref>),\n",
    "    #  (<tf.Tensor 'Train/gradients/Output_Layer/MatMul_grad/tuple/control_dependency_1:0' shape=(3, 1) dtype=float32>,\n",
    "    #   <tf.Variable 'Output_Layer/Variable:0' shape=(3, 1) dtype=float32_ref>),\n",
    "    #  (<tf.Tensor 'Train/gradients/Output_Layer/add_grad/tuple/control_dependency_1:0' shape=(1,) dtype=float32>,\n",
    "    #   <tf.Variable 'Output_Layer/Variable_1:0' shape=(1,) dtype=float32_ref>)]\n",
    "\n",
    "    with tf.name_scope(\"Init\"):\n",
    "        global_variables_init = tf.compat.v1.global_variables_initializer()\n",
    "        \n",
    "get_trainable_variables(graph=graph)\n",
    "# [<tf.Variable 'First_Layer/Hidden_layer_weights:0' shape=(5, 3) dtype=float32_ref>,\n",
    "#  <tf.Variable 'First_Layer/Biases:0' shape=(3,) dtype=float32_ref>,\n",
    "#  <tf.Variable 'Output_Layer/Output_layer_weights:0' shape=(3, 1) dtype=float32_ref>,\n",
    "#  <tf.Variable 'Output_Layer/Biases:0' shape=(1,) dtype=float32_ref>]\n",
    "\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    global_variables_init.run()\n",
    "    tf.compat.v1.get_default_graph().finalize()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    print (\"Variables before training\")\n",
    "    old_var = {}\n",
    "    for var in tf.compat.v1.global_variables():\n",
    "        old_var[var.name] = sess.run(var)\n",
    "        #print (var.name, sess.run(var))\n",
    "    print(old_var)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    miniBatches = miniBatch(data, target, batchSize = 1)\n",
    "    total_batch = len(miniBatches) \n",
    "    i=1\n",
    "    for batch in miniBatches:\n",
    "        print('\\n{}-observation\\n'.format(i))\n",
    "        xBatch = batch[0]\n",
    "        yBatch = batch[1]\n",
    "        _, loss_val, h_fc1_val, grads_and_vars_val, y_pred_val = sess.run([trainer, loss, h_fc1, grads_and_vars, y_pred], feed_dict={X: xBatch, y: yBatch})\n",
    "        print('Loss: {}'.format(loss_val))\n",
    "        print('Prediction: {}'.format(y_pred_val))\n",
    "        print('Hidden layer forward prop:{}'.format(h_fc1_val))\n",
    "        print('\\n\\n')\n",
    "        print(grads_and_vars_val)\n",
    "        i += 1\n",
    "    print(\"Optimization Finished!\")   \n",
    "    print('\\n\\n')\n",
    "    print (\"Variables after training\")\n",
    "    new_var = {}\n",
    "    for var in tf.compat.v1.global_variables():\n",
    "        new_var[var.name] = sess.run(var)\n",
    "    print(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5000b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
