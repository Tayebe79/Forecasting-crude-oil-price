{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f644964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4039396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Variables before training\n",
      "{'First_Layer/Hidden_layer_weights:0': array([[0.19, 0.55, 0.76],\n",
      "       [0.33, 0.16, 0.97],\n",
      "       [0.4 , 0.35, 0.7 ],\n",
      "       [0.51, 0.85, 0.85],\n",
      "       [0.54, 0.49, 0.57]], dtype=float32), 'First_Layer/Biases:0': array([0.1, 0.1, 0.1], dtype=float32), 'Output_Layer/Output_layer_weights:0': array([[ 0.1 ],\n",
      "       [ 0.03],\n",
      "       [-0.17]], dtype=float32), 'Output_Layer/Biases:0': array([0.1], dtype=float32)}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1-observation\n",
      "\n",
      "Loss: 0.002247666008770466\n",
      "Prediction: [[0.05259044]]\n",
      "Hidden layer forward prop:[[0.65203583 0.6772145  0.7819387 ]]\n",
      "\n",
      "\n",
      "\n",
      "[(array([[-1.0756523e-03, -3.1090478e-04,  1.3742513e-03],\n",
      "       [-2.1513047e-04, -6.2180960e-05,  2.7485026e-04],\n",
      "       [-2.1513046e-03, -6.2180957e-04,  2.7485027e-03],\n",
      "       [-0.0000000e+00, -0.0000000e+00,  0.0000000e+00],\n",
      "       [-0.0000000e+00, -0.0000000e+00,  0.0000000e+00]], dtype=float32), array([[0.19, 0.55, 0.76],\n",
      "       [0.33, 0.16, 0.97],\n",
      "       [0.4 , 0.35, 0.7 ],\n",
      "       [0.51, 0.85, 0.85],\n",
      "       [0.54, 0.49, 0.57]], dtype=float32)), (array([-0.0021513 , -0.00062181,  0.0027485 ], dtype=float32), array([0.1, 0.1, 0.1], dtype=float32)), (array([[-0.06182546],\n",
      "       [-0.06421288],\n",
      "       [-0.07414273]], dtype=float32), array([[ 0.1 ],\n",
      "       [ 0.03],\n",
      "       [-0.17]], dtype=float32)), (array([-0.09481911], dtype=float32), array([0.1], dtype=float32))]\n",
      "\n",
      "2-observation\n",
      "\n",
      "Loss: 0.17892064154148102\n",
      "Prediction: [[0.17700991]]\n",
      "Hidden layer forward prop:[[0.67573905 0.7590291  0.7974435 ]]\n",
      "\n",
      "\n",
      "\n",
      "[(array([[-0.0072801 , -0.00288298,  0.00544937],\n",
      "       [-0.0048534 , -0.00192198,  0.00363291],\n",
      "       [-0.        , -0.        ,  0.        ],\n",
      "       [-0.02426698, -0.00960992,  0.01816456],\n",
      "       [-0.        , -0.        ,  0.        ]], dtype=float32), array([[0.19053783, 0.55015546, 0.75931287],\n",
      "       [0.33010757, 0.16003108, 0.9698626 ],\n",
      "       [0.40107566, 0.3503109 , 0.69862574],\n",
      "       [0.51      , 0.85      , 0.85      ],\n",
      "       [0.54      , 0.49      , 0.57      ]], dtype=float32)), (array([-0.02426698, -0.00960992,  0.01816456], dtype=float32), array([0.10107566, 0.10031091, 0.09862575], dtype=float32)), (array([[-0.5716619 ],\n",
      "       [-0.6421236 ],\n",
      "       [-0.67462146]], dtype=float32), array([[ 0.13091274],\n",
      "       [ 0.06210644],\n",
      "       [-0.13292864]], dtype=float32)), (array([-0.8459802], dtype=float32), array([0.14740956], dtype=float32))]\n",
      "\n",
      "3-observation\n",
      "\n",
      "Loss: 0.907796323299408\n",
      "Prediction: [[1.3527834]]\n",
      "Hidden layer forward prop:[[0.74808306 0.7551234  0.88699394]]\n",
      "\n",
      "\n",
      "\n",
      "[(array([[0.10476073, 0.09450983, 0.02732672],\n",
      "       [0.13469237, 0.12151264, 0.03513435],\n",
      "       [0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        ],\n",
      "       [0.14965819, 0.13501404, 0.03903817]], dtype=float32), array([[0.19417787, 0.55159694, 0.75658816],\n",
      "       [0.33253425, 0.16099207, 0.9680461 ],\n",
      "       [0.40107566, 0.3503109 , 0.69862574],\n",
      "       [0.52213347, 0.854805  , 0.84091777],\n",
      "       [0.54      , 0.49      , 0.57      ]], dtype=float32)), (array([0.14965819, 0.13501404, 0.03903817], dtype=float32), array([0.11320915, 0.10511587, 0.08954347], dtype=float32)), (array([[1.4255223],\n",
      "       [1.4389381],\n",
      "       [1.6902263]], dtype=float32), array([[0.4167437 ],\n",
      "       [0.38316822],\n",
      "       [0.20438209]], dtype=float32)), (array([1.9055669], dtype=float32), array([0.57039964], dtype=float32))]\n",
      "\n",
      "4-observation\n",
      "\n",
      "Loss: 2.027872085571289\n",
      "Prediction: [[-1.3240337]]\n",
      "Hidden layer forward prop:[[0.6409322  0.69027746 0.81123245]]\n",
      "\n",
      "\n",
      "\n",
      "[(array([[0.15521947, 0.16381918, 0.22355723],\n",
      "       [0.01940243, 0.0204774 , 0.02794465],\n",
      "       [0.19402432, 0.20477398, 0.27944654],\n",
      "       [0.        , 0.        , 0.        ],\n",
      "       [0.        , 0.        , 0.        ]], dtype=float32), array([[0.1417975 , 0.504342  , 0.7429248 ],\n",
      "       [0.26518807, 0.10023575, 0.950479  ],\n",
      "       [0.40107566, 0.3503109 , 0.69862574],\n",
      "       [0.52213347, 0.854805  , 0.84091777],\n",
      "       [0.46517092, 0.42249298, 0.5504809 ]], dtype=float32)), (array([0.19402432, 0.20477398, 0.27944654], dtype=float32), array([0.03838006, 0.03760885, 0.07002439], dtype=float32)), (array([[-1.8254182],\n",
      "       [-1.9659568],\n",
      "       [-2.3104448]], dtype=float32), array([[-0.29601747],\n",
      "       [-0.33630085],\n",
      "       [-0.6407311 ]], dtype=float32)), (array([-2.8480675], dtype=float32), array([-0.38238382], dtype=float32))]\n",
      "Optimization Finished!\n",
      "\n",
      "\n",
      "\n",
      "Variables after training\n",
      "{'First_Layer/Hidden_layer_weights:0': array([[0.06418777, 0.42243242, 0.6311462 ],\n",
      "       [0.25548685, 0.08999705, 0.9365066 ],\n",
      "       [0.3040635 , 0.24792391, 0.5589025 ],\n",
      "       [0.52213347, 0.854805  , 0.84091777],\n",
      "       [0.46517092, 0.42249298, 0.5504809 ]], dtype=float32), 'First_Layer/Biases:0': array([-0.05863211, -0.06477814, -0.06969889], dtype=float32), 'Output_Layer/Output_layer_weights:0': array([[0.61669165],\n",
      "       [0.64667755],\n",
      "       [0.5144913 ]], dtype=float32), 'Output_Layer/Biases:0': array([1.0416499], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "#Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "num_data = np.array([[0.5, 0.1], [0.3, 0.2], [0.7, 0.9],[0.8, 0.1]])\n",
    "#(4, 2)\n",
    "# array([[0.5, 0.1],\n",
    "#        [0.3, 0.2],\n",
    "#        [0.7, 0.9],\n",
    "#        [0.8, 0.1]])\n",
    "\n",
    "cat_data = np.array([[0], [1], [2], [0]])\n",
    "#(4, 1)\n",
    "\n",
    "one_hot_cat = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]])\n",
    "#(4, 3)\n",
    "\n",
    "target = np.array([[0.1], [0.6], [0.4], [0.1]])\n",
    "# (4, 1)\n",
    "\n",
    "def get_trainable_variables(graph=tf.compat.v1.get_default_graph()):\n",
    "    return [v for v in graph.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES)]\n",
    "\n",
    "def miniBatch(x, y, batchSize):\n",
    "    numObs  = x.shape[0]\n",
    "    batches = [] \n",
    "    batchNum = math.floor(numObs / batchSize)\n",
    "    \n",
    "    if numObs % batchSize == 0:\n",
    "        for i in range(batchNum):\n",
    "            xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "            yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "            batches.append((xBatch, yBatch))\n",
    "    else:\n",
    "        for i in range(batchNum):\n",
    "            xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "            yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "            batches.append((xBatch, yBatch))\n",
    "        xBatch = x[batchNum * batchSize:, :]\n",
    "        yBatch = y[batchNum * batchSize:, :]\n",
    "        batches.append((xBatch, yBatch))\n",
    "    return batches\n",
    "\n",
    "data = np.concatenate((num_data, one_hot_cat), axis = 1)\n",
    "#(4, 5)\n",
    "\n",
    "n_features = data.shape[1]\n",
    "n_outputs = target.shape[1]\n",
    "n_hidden = 3\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('Placeholders'):\n",
    "        X = tf.compat.v1.placeholder('float', shape=[None, n_features])\n",
    "        #<tf.Tensor 'Placeholder:0' shape=(?, 5) dtype=float32>\n",
    "        y = tf.compat.v1.placeholder('float', shape=[None, n_outputs])\n",
    "        #<tf.Tensor 'Placeholder_1:0' shape=(?, 1) dtype=float32>\n",
    "\n",
    "    with tf.name_scope(\"First_Layer\"):\n",
    "        W_fc1 = tf.compat.v1.get_variable('First_Layer/Hidden_layer_weights', initializer=tf.constant(np.array([[0.19, 0.55, 0.76],[0.33, 0.16, 0.97],[0.4 , 0.35, 0.7 ],[0.51, 0.85, 0.85],[0.54, 0.49, 0.57]]), dtype=tf.float32))\n",
    "        #<tf.Variable 'First_Layer/Variable:0' shape=(5, 3) dtype=float32_ref>\n",
    "        b_fc1 = tf.compat.v1.get_variable('First_Layer/Biases', initializer=tf.constant(np.array([0.1, 0.1, 0.1]), dtype=tf.float32))\n",
    "        #<tf.Variable 'First_Layer/Variable_1:0' shape=(3,) dtype=float32_ref>\n",
    "        h_fc1 = tf.compat.v1.nn.sigmoid(tf.matmul(X, W_fc1) + b_fc1)\n",
    "        #<tf.Tensor 'First_Layer/Relu:0' shape=(?, 3) dtype=float32>\n",
    "\n",
    "    with tf.name_scope(\"Output_Layer\"):\n",
    "        W_fc2 = tf.compat.v1.get_variable('Output_Layer/Output_layer_weights', initializer=tf.constant(np.array([[ 0.10],[ 0.03],[-0.17]]), dtype=tf.float32))\n",
    "        # <tf.Variable 'Output_Layer/Variable:0' shape=(3, 1) dtype=float32_ref>\n",
    "        b_fc2 = tf.compat.v1.get_variable('Output_Layer/Biases', initializer=tf.constant(np.array([0.1]), dtype=tf.float32))\n",
    "        # <tf.Variable 'Output_Layer/Variable_1:0' shape=(1,) dtype=float32_ref>\n",
    "        y_pred = tf.compat.v1.cast(tf.matmul(h_fc1, W_fc2) + b_fc2, dtype = tf.float32)\n",
    "        #<tf.Tensor 'Output_Layer/add:0' shape=(?, 1) dtype=float32>\n",
    "\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        loss = tf.compat.v1.losses.mean_squared_error(labels = y, predictions = y_pred)\n",
    "\n",
    "    with tf.name_scope('Train'):\n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.5)\n",
    "        grads_and_vars = optimizer.compute_gradients(loss)\n",
    "        trainer = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "    # [(<tf.Tensor 'Train/gradients/First_Layer/MatMul_grad/tuple/control_dependency_1:0' shape=(5, 3) dtype=float32>,\n",
    "    #   <tf.Variable 'First_Layer/Variable:0' shape=(5, 3) dtype=float32_ref>),\n",
    "    #  (<tf.Tensor 'Train/gradients/First_Layer/add_grad/tuple/control_dependency_1:0' shape=(3,) dtype=float32>,\n",
    "    #   <tf.Variable 'First_Layer/Variable_1:0' shape=(3,) dtype=float32_ref>),\n",
    "    #  (<tf.Tensor 'Train/gradients/Output_Layer/MatMul_grad/tuple/control_dependency_1:0' shape=(3, 1) dtype=float32>,\n",
    "    #   <tf.Variable 'Output_Layer/Variable:0' shape=(3, 1) dtype=float32_ref>),\n",
    "    #  (<tf.Tensor 'Train/gradients/Output_Layer/add_grad/tuple/control_dependency_1:0' shape=(1,) dtype=float32>,\n",
    "    #   <tf.Variable 'Output_Layer/Variable_1:0' shape=(1,) dtype=float32_ref>)]\n",
    "\n",
    "    with tf.name_scope(\"Init\"):\n",
    "        global_variables_init = tf.compat.v1.global_variables_initializer()\n",
    "        \n",
    "get_trainable_variables(graph=graph)\n",
    "# [<tf.Variable 'First_Layer/Hidden_layer_weights:0' shape=(5, 3) dtype=float32_ref>,\n",
    "#  <tf.Variable 'First_Layer/Biases:0' shape=(3,) dtype=float32_ref>,\n",
    "#  <tf.Variable 'Output_Layer/Output_layer_weights:0' shape=(3, 1) dtype=float32_ref>,\n",
    "#  <tf.Variable 'Output_Layer/Biases:0' shape=(1,) dtype=float32_ref>]\n",
    "\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    global_variables_init.run()\n",
    "    tf.compat.v1.get_default_graph().finalize()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    print (\"Variables before training\")\n",
    "    old_var = {}\n",
    "    for var in tf.compat.v1.global_variables():\n",
    "        old_var[var.name] = sess.run(var)\n",
    "        #print (var.name, sess.run(var))\n",
    "    print(old_var)\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    miniBatches = miniBatch(data, target, batchSize = 1)\n",
    "    total_batch = len(miniBatches) \n",
    "    i=1\n",
    "    for batch in miniBatches:\n",
    "        print('\\n{}-observation\\n'.format(i))\n",
    "        xBatch = batch[0]\n",
    "        yBatch = batch[1]\n",
    "        _, loss_val, h_fc1_val, grads_and_vars_val, y_pred_val = sess.run([trainer, loss, h_fc1, grads_and_vars, y_pred], feed_dict={X: xBatch, y: yBatch})\n",
    "        print('Loss: {}'.format(loss_val))\n",
    "        print('Prediction: {}'.format(y_pred_val))\n",
    "        print('Hidden layer forward prop:{}'.format(h_fc1_val))\n",
    "        print('\\n\\n')\n",
    "        print(grads_and_vars_val)\n",
    "        i += 1\n",
    "    print(\"Optimization Finished!\")   \n",
    "    print('\\n\\n')\n",
    "    print (\"Variables after training\")\n",
    "    new_var = {}\n",
    "    for var in tf.compat.v1.global_variables():\n",
    "        new_var[var.name] = sess.run(var)\n",
    "    print(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02573a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.1 1.  0.  0. ]\n",
      " [0.3 0.2 0.  1.  0. ]\n",
      " [0.7 0.9 0.  0.  1. ]\n",
      " [0.8 0.1 1.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92af566e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.347254   0.000000   0.133482   0.460036   0.019191   0.800473   \n",
      "2   0.311365   0.022243   0.152132   0.484875   0.000000   0.741814   \n",
      "3   0.327134   0.057566   0.151998   0.476351   0.035270   0.713632   \n",
      "4   0.342469   0.061283   0.166047   0.490296   0.035010   0.684652   \n",
      "5   0.361827   0.091094   0.195040   0.518430   0.105290   0.662584   \n",
      "\n",
      "   var7(t-1)   var1(t)   var2(t)  \n",
      "1   0.532252  0.311365  0.022243  \n",
      "2   0.639917  0.327134  0.057566  \n",
      "3   0.649324  0.342469  0.061283  \n",
      "4   0.514890  0.361827  0.091094  \n",
      "5   0.506562  0.380968  0.154510  \n"
     ]
    }
   ],
   "source": [
    "# prepare data for lstm\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# load dataset\n",
    "dataset = df\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "#values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318fa6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1, 8) (24,) (35, 1, 8) (35,)\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967d7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 - 4s - loss: 0.2906 - val_loss: 0.6433 - 4s/epoch - 4s/step\n",
      "Epoch 2/50\n",
      "1/1 - 0s - loss: 0.2775 - val_loss: 0.6272 - 27ms/epoch - 27ms/step\n",
      "Epoch 3/50\n",
      "1/1 - 0s - loss: 0.2645 - val_loss: 0.6112 - 21ms/epoch - 21ms/step\n",
      "Epoch 4/50\n",
      "1/1 - 0s - loss: 0.2515 - val_loss: 0.5953 - 20ms/epoch - 20ms/step\n",
      "Epoch 5/50\n",
      "1/1 - 0s - loss: 0.2386 - val_loss: 0.5793 - 21ms/epoch - 21ms/step\n",
      "Epoch 6/50\n",
      "1/1 - 0s - loss: 0.2256 - val_loss: 0.5635 - 22ms/epoch - 22ms/step\n",
      "Epoch 7/50\n",
      "1/1 - 0s - loss: 0.2127 - val_loss: 0.5484 - 19ms/epoch - 19ms/step\n",
      "Epoch 8/50\n",
      "1/1 - 0s - loss: 0.1997 - val_loss: 0.5332 - 22ms/epoch - 22ms/step\n",
      "Epoch 9/50\n",
      "1/1 - 0s - loss: 0.1867 - val_loss: 0.5180 - 24ms/epoch - 24ms/step\n",
      "Epoch 10/50\n",
      "1/1 - 0s - loss: 0.1742 - val_loss: 0.5028 - 19ms/epoch - 19ms/step\n",
      "Epoch 11/50\n",
      "1/1 - 0s - loss: 0.1621 - val_loss: 0.4876 - 21ms/epoch - 21ms/step\n",
      "Epoch 12/50\n",
      "1/1 - 0s - loss: 0.1500 - val_loss: 0.4724 - 22ms/epoch - 22ms/step\n",
      "Epoch 13/50\n",
      "1/1 - 0s - loss: 0.1379 - val_loss: 0.4571 - 21ms/epoch - 21ms/step\n",
      "Epoch 14/50\n",
      "1/1 - 0s - loss: 0.1272 - val_loss: 0.4418 - 21ms/epoch - 21ms/step\n",
      "Epoch 15/50\n",
      "1/1 - 0s - loss: 0.1169 - val_loss: 0.4266 - 19ms/epoch - 19ms/step\n",
      "Epoch 16/50\n",
      "1/1 - 0s - loss: 0.1078 - val_loss: 0.4115 - 21ms/epoch - 21ms/step\n",
      "Epoch 17/50\n",
      "1/1 - 0s - loss: 0.0996 - val_loss: 0.3965 - 23ms/epoch - 23ms/step\n",
      "Epoch 18/50\n",
      "1/1 - 0s - loss: 0.0915 - val_loss: 0.3816 - 20ms/epoch - 20ms/step\n",
      "Epoch 19/50\n",
      "1/1 - 0s - loss: 0.0834 - val_loss: 0.3668 - 24ms/epoch - 24ms/step\n",
      "Epoch 20/50\n",
      "1/1 - 0s - loss: 0.0754 - val_loss: 0.3526 - 20ms/epoch - 20ms/step\n",
      "Epoch 21/50\n",
      "1/1 - 0s - loss: 0.0676 - val_loss: 0.3392 - 21ms/epoch - 21ms/step\n",
      "Epoch 22/50\n",
      "1/1 - 0s - loss: 0.0615 - val_loss: 0.3263 - 25ms/epoch - 25ms/step\n",
      "Epoch 23/50\n",
      "1/1 - 0s - loss: 0.0575 - val_loss: 0.3140 - 20ms/epoch - 20ms/step\n",
      "Epoch 24/50\n",
      "1/1 - 0s - loss: 0.0556 - val_loss: 0.3026 - 21ms/epoch - 21ms/step\n",
      "Epoch 25/50\n",
      "1/1 - 0s - loss: 0.0555 - val_loss: 0.2921 - 20ms/epoch - 20ms/step\n",
      "Epoch 26/50\n",
      "1/1 - 0s - loss: 0.0566 - val_loss: 0.2828 - 22ms/epoch - 22ms/step\n",
      "Epoch 27/50\n",
      "1/1 - 0s - loss: 0.0577 - val_loss: 0.2746 - 20ms/epoch - 20ms/step\n",
      "Epoch 28/50\n",
      "1/1 - 0s - loss: 0.0590 - val_loss: 0.2678 - 20ms/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "1/1 - 0s - loss: 0.0609 - val_loss: 0.2629 - 22ms/epoch - 22ms/step\n",
      "Epoch 30/50\n",
      "1/1 - 0s - loss: 0.0631 - val_loss: 0.2598 - 24ms/epoch - 24ms/step\n",
      "Epoch 31/50\n",
      "1/1 - 0s - loss: 0.0646 - val_loss: 0.2582 - 19ms/epoch - 19ms/step\n",
      "Epoch 32/50\n",
      "1/1 - 0s - loss: 0.0653 - val_loss: 0.2582 - 23ms/epoch - 23ms/step\n",
      "Epoch 33/50\n",
      "1/1 - 0s - loss: 0.0651 - val_loss: 0.2597 - 21ms/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "1/1 - 0s - loss: 0.0640 - val_loss: 0.2623 - 23ms/epoch - 23ms/step\n",
      "Epoch 35/50\n",
      "1/1 - 0s - loss: 0.0624 - val_loss: 0.2658 - 26ms/epoch - 26ms/step\n",
      "Epoch 36/50\n",
      "1/1 - 0s - loss: 0.0604 - val_loss: 0.2701 - 20ms/epoch - 20ms/step\n",
      "Epoch 37/50\n",
      "1/1 - 0s - loss: 0.0587 - val_loss: 0.2749 - 24ms/epoch - 24ms/step\n",
      "Epoch 38/50\n",
      "1/1 - 0s - loss: 0.0575 - val_loss: 0.2796 - 19ms/epoch - 19ms/step\n",
      "Epoch 39/50\n",
      "1/1 - 0s - loss: 0.0568 - val_loss: 0.2841 - 21ms/epoch - 21ms/step\n",
      "Epoch 40/50\n",
      "1/1 - 0s - loss: 0.0561 - val_loss: 0.2884 - 22ms/epoch - 22ms/step\n",
      "Epoch 41/50\n",
      "1/1 - 0s - loss: 0.0555 - val_loss: 0.2926 - 22ms/epoch - 22ms/step\n",
      "Epoch 42/50\n",
      "1/1 - 0s - loss: 0.0548 - val_loss: 0.2967 - 20ms/epoch - 20ms/step\n",
      "Epoch 43/50\n",
      "1/1 - 0s - loss: 0.0542 - val_loss: 0.3007 - 20ms/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "1/1 - 0s - loss: 0.0537 - val_loss: 0.3043 - 22ms/epoch - 22ms/step\n",
      "Epoch 45/50\n",
      "1/1 - 0s - loss: 0.0534 - val_loss: 0.3076 - 23ms/epoch - 23ms/step\n",
      "Epoch 46/50\n",
      "1/1 - 0s - loss: 0.0534 - val_loss: 0.3105 - 21ms/epoch - 21ms/step\n",
      "Epoch 47/50\n",
      "1/1 - 0s - loss: 0.0535 - val_loss: 0.3129 - 22ms/epoch - 22ms/step\n",
      "Epoch 48/50\n",
      "1/1 - 0s - loss: 0.0536 - val_loss: 0.3148 - 22ms/epoch - 22ms/step\n",
      "Epoch 49/50\n",
      "1/1 - 0s - loss: 0.0538 - val_loss: 0.3161 - 23ms/epoch - 23ms/step\n",
      "Epoch 50/50\n",
      "1/1 - 0s - loss: 0.0538 - val_loss: 0.3169 - 22ms/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0345b40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# make a prediction\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_X \u001b[38;5;241m=\u001b[39m test_X\u001b[38;5;241m.\u001b[39mreshape((test_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], test_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# invert scaling for forecast\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1997\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1995\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(end_step, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_outputs})\n\u001b[0;32m   1996\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1998\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1999\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2000\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2001\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2002\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2003\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m   2004\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(batch_outputs, concat, outputs)\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "...\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cabddd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.347254   0.000000   0.133482   0.460036   0.019191   0.800473   \n",
      "2   0.311365   0.022243   0.152132   0.484875   0.000000   0.741814   \n",
      "3   0.327134   0.057566   0.151998   0.476351   0.035270   0.713632   \n",
      "4   0.342469   0.061283   0.166047   0.490296   0.035010   0.684652   \n",
      "5   0.361827   0.091094   0.195040   0.518430   0.105290   0.662584   \n",
      "\n",
      "   var7(t-1)   var1(t)   var2(t)  \n",
      "1   0.532252  0.311365  0.022243  \n",
      "2   0.639917  0.327134  0.057566  \n",
      "3   0.649324  0.342469  0.061283  \n",
      "4   0.514890  0.361827  0.091094  \n",
      "5   0.506562  0.380968  0.154510  \n",
      "(50, 1, 8) (50,) (9, 1, 8) (9,)\n",
      "Epoch 1/50\n",
      "1/1 - 2s - loss: 0.2543 - val_loss: 0.7358 - 2s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "1/1 - 0s - loss: 0.2424 - val_loss: 0.7175 - 21ms/epoch - 21ms/step\n",
      "Epoch 3/50\n",
      "1/1 - 0s - loss: 0.2307 - val_loss: 0.6990 - 20ms/epoch - 20ms/step\n",
      "Epoch 4/50\n",
      "1/1 - 0s - loss: 0.2192 - val_loss: 0.6804 - 22ms/epoch - 22ms/step\n",
      "Epoch 5/50\n",
      "1/1 - 0s - loss: 0.2081 - val_loss: 0.6617 - 20ms/epoch - 20ms/step\n",
      "Epoch 6/50\n",
      "1/1 - 0s - loss: 0.1969 - val_loss: 0.6428 - 20ms/epoch - 20ms/step\n",
      "Epoch 7/50\n",
      "1/1 - 0s - loss: 0.1858 - val_loss: 0.6238 - 22ms/epoch - 22ms/step\n",
      "Epoch 8/50\n",
      "1/1 - 0s - loss: 0.1750 - val_loss: 0.6046 - 24ms/epoch - 24ms/step\n",
      "Epoch 9/50\n",
      "1/1 - 0s - loss: 0.1649 - val_loss: 0.5854 - 23ms/epoch - 23ms/step\n",
      "Epoch 10/50\n",
      "1/1 - 0s - loss: 0.1566 - val_loss: 0.5664 - 20ms/epoch - 20ms/step\n",
      "Epoch 11/50\n",
      "1/1 - 0s - loss: 0.1497 - val_loss: 0.5476 - 21ms/epoch - 21ms/step\n",
      "Epoch 12/50\n",
      "1/1 - 0s - loss: 0.1437 - val_loss: 0.5292 - 23ms/epoch - 23ms/step\n",
      "Epoch 13/50\n",
      "1/1 - 0s - loss: 0.1386 - val_loss: 0.5111 - 22ms/epoch - 22ms/step\n",
      "Epoch 14/50\n",
      "1/1 - 0s - loss: 0.1345 - val_loss: 0.4935 - 20ms/epoch - 20ms/step\n",
      "Epoch 15/50\n",
      "1/1 - 0s - loss: 0.1321 - val_loss: 0.4770 - 20ms/epoch - 20ms/step\n",
      "Epoch 16/50\n",
      "1/1 - 0s - loss: 0.1318 - val_loss: 0.4622 - 22ms/epoch - 22ms/step\n",
      "Epoch 17/50\n",
      "1/1 - 0s - loss: 0.1330 - val_loss: 0.4494 - 20ms/epoch - 20ms/step\n",
      "Epoch 18/50\n",
      "1/1 - 0s - loss: 0.1343 - val_loss: 0.4383 - 23ms/epoch - 23ms/step\n",
      "Epoch 19/50\n",
      "1/1 - 0s - loss: 0.1355 - val_loss: 0.4291 - 21ms/epoch - 21ms/step\n",
      "Epoch 20/50\n",
      "1/1 - 0s - loss: 0.1366 - val_loss: 0.4216 - 20ms/epoch - 20ms/step\n",
      "Epoch 21/50\n",
      "1/1 - 0s - loss: 0.1375 - val_loss: 0.4158 - 21ms/epoch - 21ms/step\n",
      "Epoch 22/50\n",
      "1/1 - 0s - loss: 0.1382 - val_loss: 0.4119 - 20ms/epoch - 20ms/step\n",
      "Epoch 23/50\n",
      "1/1 - 0s - loss: 0.1386 - val_loss: 0.4096 - 21ms/epoch - 21ms/step\n",
      "Epoch 24/50\n",
      "1/1 - 0s - loss: 0.1387 - val_loss: 0.4088 - 19ms/epoch - 19ms/step\n",
      "Epoch 25/50\n",
      "1/1 - 0s - loss: 0.1384 - val_loss: 0.4094 - 22ms/epoch - 22ms/step\n",
      "Epoch 26/50\n",
      "1/1 - 0s - loss: 0.1379 - val_loss: 0.4111 - 21ms/epoch - 21ms/step\n",
      "Epoch 27/50\n",
      "1/1 - 0s - loss: 0.1370 - val_loss: 0.4140 - 20ms/epoch - 20ms/step\n",
      "Epoch 28/50\n",
      "1/1 - 0s - loss: 0.1360 - val_loss: 0.4176 - 20ms/epoch - 20ms/step\n",
      "Epoch 29/50\n",
      "1/1 - 0s - loss: 0.1349 - val_loss: 0.4219 - 21ms/epoch - 21ms/step\n",
      "Epoch 30/50\n",
      "1/1 - 0s - loss: 0.1337 - val_loss: 0.4268 - 22ms/epoch - 22ms/step\n",
      "Epoch 31/50\n",
      "1/1 - 0s - loss: 0.1325 - val_loss: 0.4320 - 20ms/epoch - 20ms/step\n",
      "Epoch 32/50\n",
      "1/1 - 0s - loss: 0.1313 - val_loss: 0.4374 - 22ms/epoch - 22ms/step\n",
      "Epoch 33/50\n",
      "1/1 - 0s - loss: 0.1302 - val_loss: 0.4429 - 21ms/epoch - 21ms/step\n",
      "Epoch 34/50\n",
      "1/1 - 0s - loss: 0.1291 - val_loss: 0.4485 - 20ms/epoch - 20ms/step\n",
      "Epoch 35/50\n",
      "1/1 - 0s - loss: 0.1280 - val_loss: 0.4542 - 22ms/epoch - 22ms/step\n",
      "Epoch 36/50\n",
      "1/1 - 0s - loss: 0.1270 - val_loss: 0.4596 - 21ms/epoch - 21ms/step\n",
      "Epoch 37/50\n",
      "1/1 - 0s - loss: 0.1265 - val_loss: 0.4644 - 20ms/epoch - 20ms/step\n",
      "Epoch 38/50\n",
      "1/1 - 0s - loss: 0.1260 - val_loss: 0.4687 - 21ms/epoch - 21ms/step\n",
      "Epoch 39/50\n",
      "1/1 - 0s - loss: 0.1257 - val_loss: 0.4717 - 21ms/epoch - 21ms/step\n",
      "Epoch 40/50\n",
      "1/1 - 0s - loss: 0.1259 - val_loss: 0.4733 - 21ms/epoch - 21ms/step\n",
      "Epoch 41/50\n",
      "1/1 - 0s - loss: 0.1259 - val_loss: 0.4738 - 21ms/epoch - 21ms/step\n",
      "Epoch 42/50\n",
      "1/1 - 0s - loss: 0.1259 - val_loss: 0.4730 - 22ms/epoch - 22ms/step\n",
      "Epoch 43/50\n",
      "1/1 - 0s - loss: 0.1256 - val_loss: 0.4710 - 20ms/epoch - 20ms/step\n",
      "Epoch 44/50\n",
      "1/1 - 0s - loss: 0.1252 - val_loss: 0.4679 - 22ms/epoch - 22ms/step\n",
      "Epoch 45/50\n",
      "1/1 - 0s - loss: 0.1246 - val_loss: 0.4639 - 22ms/epoch - 22ms/step\n",
      "Epoch 46/50\n",
      "1/1 - 0s - loss: 0.1238 - val_loss: 0.4591 - 20ms/epoch - 20ms/step\n",
      "Epoch 47/50\n",
      "1/1 - 0s - loss: 0.1231 - val_loss: 0.4541 - 21ms/epoch - 21ms/step\n",
      "Epoch 48/50\n",
      "1/1 - 0s - loss: 0.1225 - val_loss: 0.4489 - 22ms/epoch - 22ms/step\n",
      "Epoch 49/50\n",
      "1/1 - 0s - loss: 0.1221 - val_loss: 0.4442 - 21ms/epoch - 21ms/step\n",
      "Epoch 50/50\n",
      "1/1 - 0s - loss: 0.1217 - val_loss: 0.4399 - 22ms/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9,8) (7,) (9,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 86>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# invert scaling for forecast\u001b[39;00m\n\u001b[0;32m     85\u001b[0m inv_yhat \u001b[38;5;241m=\u001b[39m concatenate((yhat, test_X[:, \u001b[38;5;241m1\u001b[39m:]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m inv_yhat \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minv_yhat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m inv_yhat \u001b[38;5;241m=\u001b[39m inv_yhat[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# invert scaling for actual\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:532\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    526\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    528\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    529\u001b[0m     X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m )\n\u001b[1;32m--> 532\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    533\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9,8) (7,) (9,8) "
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = df\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "#values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 50\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c327a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 28)\n",
      "[0.9661609  0.87901986 0.9999999  0.92130005 0.84045947 0.89171636\n",
      " 0.78074586]\n",
      "(50, 18) 50 (50,)\n",
      "(50, 3, 6) (50,) (7, 3, 6) (7,)\n",
      "Epoch 1/600\n",
      "1/1 - 2s - loss: 0.4095 - 2s/epoch - 2s/step\n",
      "Epoch 2/600\n",
      "1/1 - 0s - loss: 0.3792 - 3ms/epoch - 3ms/step\n",
      "Epoch 3/600\n",
      "1/1 - 0s - loss: 0.3491 - 3ms/epoch - 3ms/step\n",
      "Epoch 4/600\n",
      "1/1 - 0s - loss: 0.3201 - 4ms/epoch - 4ms/step\n",
      "Epoch 5/600\n",
      "1/1 - 0s - loss: 0.2926 - 3ms/epoch - 3ms/step\n",
      "Epoch 6/600\n",
      "1/1 - 0s - loss: 0.2650 - 4ms/epoch - 4ms/step\n",
      "Epoch 7/600\n",
      "1/1 - 0s - loss: 0.2382 - 4ms/epoch - 4ms/step\n",
      "Epoch 8/600\n",
      "1/1 - 0s - loss: 0.2123 - 3ms/epoch - 3ms/step\n",
      "Epoch 9/600\n",
      "1/1 - 0s - loss: 0.1871 - 4ms/epoch - 4ms/step\n",
      "Epoch 10/600\n",
      "1/1 - 0s - loss: 0.1667 - 3ms/epoch - 3ms/step\n",
      "Epoch 11/600\n",
      "1/1 - 0s - loss: 0.1539 - 4ms/epoch - 4ms/step\n",
      "Epoch 12/600\n",
      "1/1 - 0s - loss: 0.1445 - 4ms/epoch - 4ms/step\n",
      "Epoch 13/600\n",
      "1/1 - 0s - loss: 0.1408 - 4ms/epoch - 4ms/step\n",
      "Epoch 14/600\n",
      "1/1 - 0s - loss: 0.1451 - 4ms/epoch - 4ms/step\n",
      "Epoch 15/600\n",
      "1/1 - 0s - loss: 0.1501 - 4ms/epoch - 4ms/step\n",
      "Epoch 16/600\n",
      "1/1 - 0s - loss: 0.1560 - 5ms/epoch - 5ms/step\n",
      "Epoch 17/600\n",
      "1/1 - 0s - loss: 0.1609 - 3ms/epoch - 3ms/step\n",
      "Epoch 18/600\n",
      "1/1 - 0s - loss: 0.1640 - 4ms/epoch - 4ms/step\n",
      "Epoch 19/600\n",
      "1/1 - 0s - loss: 0.1653 - 3ms/epoch - 3ms/step\n",
      "Epoch 20/600\n",
      "1/1 - 0s - loss: 0.1651 - 4ms/epoch - 4ms/step\n",
      "Epoch 21/600\n",
      "1/1 - 0s - loss: 0.1634 - 5ms/epoch - 5ms/step\n",
      "Epoch 22/600\n",
      "1/1 - 0s - loss: 0.1605 - 4ms/epoch - 4ms/step\n",
      "Epoch 23/600\n",
      "1/1 - 0s - loss: 0.1566 - 3ms/epoch - 3ms/step\n",
      "Epoch 24/600\n",
      "1/1 - 0s - loss: 0.1523 - 4ms/epoch - 4ms/step\n",
      "Epoch 25/600\n",
      "1/1 - 0s - loss: 0.1478 - 4ms/epoch - 4ms/step\n",
      "Epoch 26/600\n",
      "1/1 - 0s - loss: 0.1440 - 3ms/epoch - 3ms/step\n",
      "Epoch 27/600\n",
      "1/1 - 0s - loss: 0.1410 - 4ms/epoch - 4ms/step\n",
      "Epoch 28/600\n",
      "1/1 - 0s - loss: 0.1379 - 4ms/epoch - 4ms/step\n",
      "Epoch 29/600\n",
      "1/1 - 0s - loss: 0.1357 - 3ms/epoch - 3ms/step\n",
      "Epoch 30/600\n",
      "1/1 - 0s - loss: 0.1353 - 4ms/epoch - 4ms/step\n",
      "Epoch 31/600\n",
      "1/1 - 0s - loss: 0.1363 - 4ms/epoch - 4ms/step\n",
      "Epoch 32/600\n",
      "1/1 - 0s - loss: 0.1375 - 4ms/epoch - 4ms/step\n",
      "Epoch 33/600\n",
      "1/1 - 0s - loss: 0.1384 - 3ms/epoch - 3ms/step\n",
      "Epoch 34/600\n",
      "1/1 - 0s - loss: 0.1390 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/600\n",
      "1/1 - 0s - loss: 0.1389 - 3ms/epoch - 3ms/step\n",
      "Epoch 36/600\n",
      "1/1 - 0s - loss: 0.1383 - 4ms/epoch - 4ms/step\n",
      "Epoch 37/600\n",
      "1/1 - 0s - loss: 0.1371 - 4ms/epoch - 4ms/step\n",
      "Epoch 38/600\n",
      "1/1 - 0s - loss: 0.1357 - 4ms/epoch - 4ms/step\n",
      "Epoch 39/600\n",
      "1/1 - 0s - loss: 0.1341 - 4ms/epoch - 4ms/step\n",
      "Epoch 40/600\n",
      "1/1 - 0s - loss: 0.1324 - 4ms/epoch - 4ms/step\n",
      "Epoch 41/600\n",
      "1/1 - 0s - loss: 0.1307 - 3ms/epoch - 3ms/step\n",
      "Epoch 42/600\n",
      "1/1 - 0s - loss: 0.1299 - 3ms/epoch - 3ms/step\n",
      "Epoch 43/600\n",
      "1/1 - 0s - loss: 0.1295 - 4ms/epoch - 4ms/step\n",
      "Epoch 44/600\n",
      "1/1 - 0s - loss: 0.1296 - 3ms/epoch - 3ms/step\n",
      "Epoch 45/600\n",
      "1/1 - 0s - loss: 0.1296 - 4ms/epoch - 4ms/step\n",
      "Epoch 46/600\n",
      "1/1 - 0s - loss: 0.1295 - 4ms/epoch - 4ms/step\n",
      "Epoch 47/600\n",
      "1/1 - 0s - loss: 0.1292 - 3ms/epoch - 3ms/step\n",
      "Epoch 48/600\n",
      "1/1 - 0s - loss: 0.1287 - 4ms/epoch - 4ms/step\n",
      "Epoch 49/600\n",
      "1/1 - 0s - loss: 0.1279 - 4ms/epoch - 4ms/step\n",
      "Epoch 50/600\n",
      "1/1 - 0s - loss: 0.1270 - 4ms/epoch - 4ms/step\n",
      "Epoch 51/600\n",
      "1/1 - 0s - loss: 0.1260 - 4ms/epoch - 4ms/step\n",
      "Epoch 52/600\n",
      "1/1 - 0s - loss: 0.1249 - 4ms/epoch - 4ms/step\n",
      "Epoch 53/600\n",
      "1/1 - 0s - loss: 0.1240 - 4ms/epoch - 4ms/step\n",
      "Epoch 54/600\n",
      "1/1 - 0s - loss: 0.1235 - 3ms/epoch - 3ms/step\n",
      "Epoch 55/600\n",
      "1/1 - 0s - loss: 0.1230 - 4ms/epoch - 4ms/step\n",
      "Epoch 56/600\n",
      "1/1 - 0s - loss: 0.1226 - 4ms/epoch - 4ms/step\n",
      "Epoch 57/600\n",
      "1/1 - 0s - loss: 0.1224 - 4ms/epoch - 4ms/step\n",
      "Epoch 58/600\n",
      "1/1 - 0s - loss: 0.1219 - 3ms/epoch - 3ms/step\n",
      "Epoch 59/600\n",
      "1/1 - 0s - loss: 0.1211 - 3ms/epoch - 3ms/step\n",
      "Epoch 60/600\n",
      "1/1 - 0s - loss: 0.1202 - 3ms/epoch - 3ms/step\n",
      "Epoch 61/600\n",
      "1/1 - 0s - loss: 0.1194 - 4ms/epoch - 4ms/step\n",
      "Epoch 62/600\n",
      "1/1 - 0s - loss: 0.1185 - 3ms/epoch - 3ms/step\n",
      "Epoch 63/600\n",
      "1/1 - 0s - loss: 0.1176 - 4ms/epoch - 4ms/step\n",
      "Epoch 64/600\n",
      "1/1 - 0s - loss: 0.1169 - 4ms/epoch - 4ms/step\n",
      "Epoch 65/600\n",
      "1/1 - 0s - loss: 0.1162 - 3ms/epoch - 3ms/step\n",
      "Epoch 66/600\n",
      "1/1 - 0s - loss: 0.1157 - 4ms/epoch - 4ms/step\n",
      "Epoch 67/600\n",
      "1/1 - 0s - loss: 0.1150 - 4ms/epoch - 4ms/step\n",
      "Epoch 68/600\n",
      "1/1 - 0s - loss: 0.1141 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/600\n",
      "1/1 - 0s - loss: 0.1132 - 4ms/epoch - 4ms/step\n",
      "Epoch 70/600\n",
      "1/1 - 0s - loss: 0.1123 - 3ms/epoch - 3ms/step\n",
      "Epoch 71/600\n",
      "1/1 - 0s - loss: 0.1114 - 4ms/epoch - 4ms/step\n",
      "Epoch 72/600\n",
      "1/1 - 0s - loss: 0.1106 - 3ms/epoch - 3ms/step\n",
      "Epoch 73/600\n",
      "1/1 - 0s - loss: 0.1099 - 4ms/epoch - 4ms/step\n",
      "Epoch 74/600\n",
      "1/1 - 0s - loss: 0.1090 - 4ms/epoch - 4ms/step\n",
      "Epoch 75/600\n",
      "1/1 - 0s - loss: 0.1081 - 4ms/epoch - 4ms/step\n",
      "Epoch 76/600\n",
      "1/1 - 0s - loss: 0.1071 - 3ms/epoch - 3ms/step\n",
      "Epoch 77/600\n",
      "1/1 - 0s - loss: 0.1061 - 3ms/epoch - 3ms/step\n",
      "Epoch 78/600\n",
      "1/1 - 0s - loss: 0.1052 - 4ms/epoch - 4ms/step\n",
      "Epoch 79/600\n",
      "1/1 - 0s - loss: 0.1042 - 3ms/epoch - 3ms/step\n",
      "Epoch 80/600\n",
      "1/1 - 0s - loss: 0.1032 - 4ms/epoch - 4ms/step\n",
      "Epoch 81/600\n",
      "1/1 - 0s - loss: 0.1022 - 4ms/epoch - 4ms/step\n",
      "Epoch 82/600\n",
      "1/1 - 0s - loss: 0.1011 - 4ms/epoch - 4ms/step\n",
      "Epoch 83/600\n",
      "1/1 - 0s - loss: 0.1000 - 3ms/epoch - 3ms/step\n",
      "Epoch 84/600\n",
      "1/1 - 0s - loss: 0.0989 - 3ms/epoch - 3ms/step\n",
      "Epoch 85/600\n",
      "1/1 - 0s - loss: 0.0978 - 4ms/epoch - 4ms/step\n",
      "Epoch 86/600\n",
      "1/1 - 0s - loss: 0.0967 - 3ms/epoch - 3ms/step\n",
      "Epoch 87/600\n",
      "1/1 - 0s - loss: 0.0957 - 3ms/epoch - 3ms/step\n",
      "Epoch 88/600\n",
      "1/1 - 0s - loss: 0.0946 - 9ms/epoch - 9ms/step\n",
      "Epoch 89/600\n",
      "1/1 - 0s - loss: 0.0936 - 4ms/epoch - 4ms/step\n",
      "Epoch 90/600\n",
      "1/1 - 0s - loss: 0.0925 - 4ms/epoch - 4ms/step\n",
      "Epoch 91/600\n",
      "1/1 - 0s - loss: 0.0914 - 4ms/epoch - 4ms/step\n",
      "Epoch 92/600\n",
      "1/1 - 0s - loss: 0.0902 - 4ms/epoch - 4ms/step\n",
      "Epoch 93/600\n",
      "1/1 - 0s - loss: 0.0890 - 3ms/epoch - 3ms/step\n",
      "Epoch 94/600\n",
      "1/1 - 0s - loss: 0.0879 - 4ms/epoch - 4ms/step\n",
      "Epoch 95/600\n",
      "1/1 - 0s - loss: 0.0869 - 5ms/epoch - 5ms/step\n",
      "Epoch 96/600\n",
      "1/1 - 0s - loss: 0.0861 - 3ms/epoch - 3ms/step\n",
      "Epoch 97/600\n",
      "1/1 - 0s - loss: 0.0852 - 4ms/epoch - 4ms/step\n",
      "Epoch 98/600\n",
      "1/1 - 0s - loss: 0.0842 - 4ms/epoch - 4ms/step\n",
      "Epoch 99/600\n",
      "1/1 - 0s - loss: 0.0833 - 3ms/epoch - 3ms/step\n",
      "Epoch 100/600\n",
      "1/1 - 0s - loss: 0.0824 - 4ms/epoch - 4ms/step\n",
      "Epoch 101/600\n",
      "1/1 - 0s - loss: 0.0815 - 3ms/epoch - 3ms/step\n",
      "Epoch 102/600\n",
      "1/1 - 0s - loss: 0.0808 - 4ms/epoch - 4ms/step\n",
      "Epoch 103/600\n",
      "1/1 - 0s - loss: 0.0800 - 3ms/epoch - 3ms/step\n",
      "Epoch 104/600\n",
      "1/1 - 0s - loss: 0.0790 - 3ms/epoch - 3ms/step\n",
      "Epoch 105/600\n",
      "1/1 - 0s - loss: 0.0780 - 3ms/epoch - 3ms/step\n",
      "Epoch 106/600\n",
      "1/1 - 0s - loss: 0.0771 - 3ms/epoch - 3ms/step\n",
      "Epoch 107/600\n",
      "1/1 - 0s - loss: 0.0762 - 4ms/epoch - 4ms/step\n",
      "Epoch 108/600\n",
      "1/1 - 0s - loss: 0.0760 - 3ms/epoch - 3ms/step\n",
      "Epoch 109/600\n",
      "1/1 - 0s - loss: 0.0752 - 4ms/epoch - 4ms/step\n",
      "Epoch 110/600\n",
      "1/1 - 0s - loss: 0.0743 - 3ms/epoch - 3ms/step\n",
      "Epoch 111/600\n",
      "1/1 - 0s - loss: 0.0738 - 3ms/epoch - 3ms/step\n",
      "Epoch 112/600\n",
      "1/1 - 0s - loss: 0.0740 - 4ms/epoch - 4ms/step\n",
      "Epoch 113/600\n",
      "1/1 - 0s - loss: 0.0734 - 3ms/epoch - 3ms/step\n",
      "Epoch 114/600\n",
      "1/1 - 0s - loss: 0.0730 - 4ms/epoch - 4ms/step\n",
      "Epoch 115/600\n",
      "1/1 - 0s - loss: 0.0728 - 4ms/epoch - 4ms/step\n",
      "Epoch 116/600\n",
      "1/1 - 0s - loss: 0.0728 - 3ms/epoch - 3ms/step\n",
      "Epoch 117/600\n",
      "1/1 - 0s - loss: 0.0725 - 4ms/epoch - 4ms/step\n",
      "Epoch 118/600\n",
      "1/1 - 0s - loss: 0.0719 - 4ms/epoch - 4ms/step\n",
      "Epoch 119/600\n",
      "1/1 - 0s - loss: 0.0712 - 4ms/epoch - 4ms/step\n",
      "Epoch 120/600\n",
      "1/1 - 0s - loss: 0.0704 - 3ms/epoch - 3ms/step\n",
      "Epoch 121/600\n",
      "1/1 - 0s - loss: 0.0701 - 4ms/epoch - 4ms/step\n",
      "Epoch 122/600\n",
      "1/1 - 0s - loss: 0.0700 - 4ms/epoch - 4ms/step\n",
      "Epoch 123/600\n",
      "1/1 - 0s - loss: 0.0690 - 4ms/epoch - 4ms/step\n",
      "Epoch 124/600\n",
      "1/1 - 0s - loss: 0.0684 - 3ms/epoch - 3ms/step\n",
      "Epoch 125/600\n",
      "1/1 - 0s - loss: 0.0679 - 3ms/epoch - 3ms/step\n",
      "Epoch 126/600\n",
      "1/1 - 0s - loss: 0.0676 - 4ms/epoch - 4ms/step\n",
      "Epoch 127/600\n",
      "1/1 - 0s - loss: 0.0670 - 3ms/epoch - 3ms/step\n",
      "Epoch 128/600\n",
      "1/1 - 0s - loss: 0.0666 - 3ms/epoch - 3ms/step\n",
      "Epoch 129/600\n",
      "1/1 - 0s - loss: 0.0663 - 4ms/epoch - 4ms/step\n",
      "Epoch 130/600\n",
      "1/1 - 0s - loss: 0.0659 - 3ms/epoch - 3ms/step\n",
      "Epoch 131/600\n",
      "1/1 - 0s - loss: 0.0656 - 3ms/epoch - 3ms/step\n",
      "Epoch 132/600\n",
      "1/1 - 0s - loss: 0.0654 - 4ms/epoch - 4ms/step\n",
      "Epoch 133/600\n",
      "1/1 - 0s - loss: 0.0652 - 3ms/epoch - 3ms/step\n",
      "Epoch 134/600\n",
      "1/1 - 0s - loss: 0.0650 - 3ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/600\n",
      "1/1 - 0s - loss: 0.0647 - 3ms/epoch - 3ms/step\n",
      "Epoch 136/600\n",
      "1/1 - 0s - loss: 0.0645 - 4ms/epoch - 4ms/step\n",
      "Epoch 137/600\n",
      "1/1 - 0s - loss: 0.0642 - 3ms/epoch - 3ms/step\n",
      "Epoch 138/600\n",
      "1/1 - 0s - loss: 0.0640 - 3ms/epoch - 3ms/step\n",
      "Epoch 139/600\n",
      "1/1 - 0s - loss: 0.0638 - 5ms/epoch - 5ms/step\n",
      "Epoch 140/600\n",
      "1/1 - 0s - loss: 0.0635 - 3ms/epoch - 3ms/step\n",
      "Epoch 141/600\n",
      "1/1 - 0s - loss: 0.0632 - 4ms/epoch - 4ms/step\n",
      "Epoch 142/600\n",
      "1/1 - 0s - loss: 0.0630 - 3ms/epoch - 3ms/step\n",
      "Epoch 143/600\n",
      "1/1 - 0s - loss: 0.0627 - 3ms/epoch - 3ms/step\n",
      "Epoch 144/600\n",
      "1/1 - 0s - loss: 0.0624 - 3ms/epoch - 3ms/step\n",
      "Epoch 145/600\n",
      "1/1 - 0s - loss: 0.0622 - 3ms/epoch - 3ms/step\n",
      "Epoch 146/600\n",
      "1/1 - 0s - loss: 0.0619 - 3ms/epoch - 3ms/step\n",
      "Epoch 147/600\n",
      "1/1 - 0s - loss: 0.0617 - 3ms/epoch - 3ms/step\n",
      "Epoch 148/600\n",
      "1/1 - 0s - loss: 0.0616 - 3ms/epoch - 3ms/step\n",
      "Epoch 149/600\n",
      "1/1 - 0s - loss: 0.0614 - 3ms/epoch - 3ms/step\n",
      "Epoch 150/600\n",
      "1/1 - 0s - loss: 0.0612 - 4ms/epoch - 4ms/step\n",
      "Epoch 151/600\n",
      "1/1 - 0s - loss: 0.0611 - 4ms/epoch - 4ms/step\n",
      "Epoch 152/600\n",
      "1/1 - 0s - loss: 0.0608 - 4ms/epoch - 4ms/step\n",
      "Epoch 153/600\n",
      "1/1 - 0s - loss: 0.0606 - 3ms/epoch - 3ms/step\n",
      "Epoch 154/600\n",
      "1/1 - 0s - loss: 0.0604 - 4ms/epoch - 4ms/step\n",
      "Epoch 155/600\n",
      "1/1 - 0s - loss: 0.0602 - 3ms/epoch - 3ms/step\n",
      "Epoch 156/600\n",
      "1/1 - 0s - loss: 0.0600 - 3ms/epoch - 3ms/step\n",
      "Epoch 157/600\n",
      "1/1 - 0s - loss: 0.0599 - 3ms/epoch - 3ms/step\n",
      "Epoch 158/600\n",
      "1/1 - 0s - loss: 0.0596 - 3ms/epoch - 3ms/step\n",
      "Epoch 159/600\n",
      "1/1 - 0s - loss: 0.0595 - 4ms/epoch - 4ms/step\n",
      "Epoch 160/600\n",
      "1/1 - 0s - loss: 0.0593 - 3ms/epoch - 3ms/step\n",
      "Epoch 161/600\n",
      "1/1 - 0s - loss: 0.0591 - 3ms/epoch - 3ms/step\n",
      "Epoch 162/600\n",
      "1/1 - 0s - loss: 0.0589 - 3ms/epoch - 3ms/step\n",
      "Epoch 163/600\n",
      "1/1 - 0s - loss: 0.0588 - 3ms/epoch - 3ms/step\n",
      "Epoch 164/600\n",
      "1/1 - 0s - loss: 0.0586 - 3ms/epoch - 3ms/step\n",
      "Epoch 165/600\n",
      "1/1 - 0s - loss: 0.0585 - 3ms/epoch - 3ms/step\n",
      "Epoch 166/600\n",
      "1/1 - 0s - loss: 0.0583 - 3ms/epoch - 3ms/step\n",
      "Epoch 167/600\n",
      "1/1 - 0s - loss: 0.0582 - 3ms/epoch - 3ms/step\n",
      "Epoch 168/600\n",
      "1/1 - 0s - loss: 0.0580 - 3ms/epoch - 3ms/step\n",
      "Epoch 169/600\n",
      "1/1 - 0s - loss: 0.0581 - 3ms/epoch - 3ms/step\n",
      "Epoch 170/600\n",
      "1/1 - 0s - loss: 0.0576 - 3ms/epoch - 3ms/step\n",
      "Epoch 171/600\n",
      "1/1 - 0s - loss: 0.0575 - 3ms/epoch - 3ms/step\n",
      "Epoch 172/600\n",
      "1/1 - 0s - loss: 0.0575 - 3ms/epoch - 3ms/step\n",
      "Epoch 173/600\n",
      "1/1 - 0s - loss: 0.0574 - 3ms/epoch - 3ms/step\n",
      "Epoch 174/600\n",
      "1/1 - 0s - loss: 0.0573 - 4ms/epoch - 4ms/step\n",
      "Epoch 175/600\n",
      "1/1 - 0s - loss: 0.0571 - 3ms/epoch - 3ms/step\n",
      "Epoch 176/600\n",
      "1/1 - 0s - loss: 0.0572 - 3ms/epoch - 3ms/step\n",
      "Epoch 177/600\n",
      "1/1 - 0s - loss: 0.0568 - 4ms/epoch - 4ms/step\n",
      "Epoch 178/600\n",
      "1/1 - 0s - loss: 0.0567 - 3ms/epoch - 3ms/step\n",
      "Epoch 179/600\n",
      "1/1 - 0s - loss: 0.0568 - 3ms/epoch - 3ms/step\n",
      "Epoch 180/600\n",
      "1/1 - 0s - loss: 0.0566 - 4ms/epoch - 4ms/step\n",
      "Epoch 181/600\n",
      "1/1 - 0s - loss: 0.0564 - 3ms/epoch - 3ms/step\n",
      "Epoch 182/600\n",
      "1/1 - 0s - loss: 0.0562 - 3ms/epoch - 3ms/step\n",
      "Epoch 183/600\n",
      "1/1 - 0s - loss: 0.0566 - 4ms/epoch - 4ms/step\n",
      "Epoch 184/600\n",
      "1/1 - 0s - loss: 0.0560 - 4ms/epoch - 4ms/step\n",
      "Epoch 185/600\n",
      "1/1 - 0s - loss: 0.0562 - 3ms/epoch - 3ms/step\n",
      "Epoch 186/600\n",
      "1/1 - 0s - loss: 0.0558 - 3ms/epoch - 3ms/step\n",
      "Epoch 187/600\n",
      "1/1 - 0s - loss: 0.0562 - 3ms/epoch - 3ms/step\n",
      "Epoch 188/600\n",
      "1/1 - 0s - loss: 0.0556 - 3ms/epoch - 3ms/step\n",
      "Epoch 189/600\n",
      "1/1 - 0s - loss: 0.0556 - 3ms/epoch - 3ms/step\n",
      "Epoch 190/600\n",
      "1/1 - 0s - loss: 0.0554 - 3ms/epoch - 3ms/step\n",
      "Epoch 191/600\n",
      "1/1 - 0s - loss: 0.0553 - 3ms/epoch - 3ms/step\n",
      "Epoch 192/600\n",
      "1/1 - 0s - loss: 0.0555 - 3ms/epoch - 3ms/step\n",
      "Epoch 193/600\n",
      "1/1 - 0s - loss: 0.0552 - 3ms/epoch - 3ms/step\n",
      "Epoch 194/600\n",
      "1/1 - 0s - loss: 0.0555 - 3ms/epoch - 3ms/step\n",
      "Epoch 195/600\n",
      "1/1 - 0s - loss: 0.0552 - 3ms/epoch - 3ms/step\n",
      "Epoch 196/600\n",
      "1/1 - 0s - loss: 0.0551 - 3ms/epoch - 3ms/step\n",
      "Epoch 197/600\n",
      "1/1 - 0s - loss: 0.0551 - 3ms/epoch - 3ms/step\n",
      "Epoch 198/600\n",
      "1/1 - 0s - loss: 0.0550 - 3ms/epoch - 3ms/step\n",
      "Epoch 199/600\n",
      "1/1 - 0s - loss: 0.0551 - 3ms/epoch - 3ms/step\n",
      "Epoch 200/600\n",
      "1/1 - 0s - loss: 0.0549 - 3ms/epoch - 3ms/step\n",
      "Epoch 201/600\n",
      "1/1 - 0s - loss: 0.0550 - 4ms/epoch - 4ms/step\n",
      "Epoch 202/600\n",
      "1/1 - 0s - loss: 0.0549 - 4ms/epoch - 4ms/step\n",
      "Epoch 203/600\n",
      "1/1 - 0s - loss: 0.0548 - 3ms/epoch - 3ms/step\n",
      "Epoch 204/600\n",
      "1/1 - 0s - loss: 0.0548 - 4ms/epoch - 4ms/step\n",
      "Epoch 205/600\n",
      "1/1 - 0s - loss: 0.0547 - 5ms/epoch - 5ms/step\n",
      "Epoch 206/600\n",
      "1/1 - 0s - loss: 0.0549 - 3ms/epoch - 3ms/step\n",
      "Epoch 207/600\n",
      "1/1 - 0s - loss: 0.0546 - 3ms/epoch - 3ms/step\n",
      "Epoch 208/600\n",
      "1/1 - 0s - loss: 0.0546 - 3ms/epoch - 3ms/step\n",
      "Epoch 209/600\n",
      "1/1 - 0s - loss: 0.0545 - 3ms/epoch - 3ms/step\n",
      "Epoch 210/600\n",
      "1/1 - 0s - loss: 0.0545 - 4ms/epoch - 4ms/step\n",
      "Epoch 211/600\n",
      "1/1 - 0s - loss: 0.0545 - 3ms/epoch - 3ms/step\n",
      "Epoch 212/600\n",
      "1/1 - 0s - loss: 0.0544 - 3ms/epoch - 3ms/step\n",
      "Epoch 213/600\n",
      "1/1 - 0s - loss: 0.0544 - 3ms/epoch - 3ms/step\n",
      "Epoch 214/600\n",
      "1/1 - 0s - loss: 0.0544 - 3ms/epoch - 3ms/step\n",
      "Epoch 215/600\n",
      "1/1 - 0s - loss: 0.0544 - 4ms/epoch - 4ms/step\n",
      "Epoch 216/600\n",
      "1/1 - 0s - loss: 0.0542 - 3ms/epoch - 3ms/step\n",
      "Epoch 217/600\n",
      "1/1 - 0s - loss: 0.0544 - 4ms/epoch - 4ms/step\n",
      "Epoch 218/600\n",
      "1/1 - 0s - loss: 0.0544 - 4ms/epoch - 4ms/step\n",
      "Epoch 219/600\n",
      "1/1 - 0s - loss: 0.0543 - 3ms/epoch - 3ms/step\n",
      "Epoch 220/600\n",
      "1/1 - 0s - loss: 0.0543 - 3ms/epoch - 3ms/step\n",
      "Epoch 221/600\n",
      "1/1 - 0s - loss: 0.0540 - 3ms/epoch - 3ms/step\n",
      "Epoch 222/600\n",
      "1/1 - 0s - loss: 0.0544 - 4ms/epoch - 4ms/step\n",
      "Epoch 223/600\n",
      "1/1 - 0s - loss: 0.0540 - 3ms/epoch - 3ms/step\n",
      "Epoch 224/600\n",
      "1/1 - 0s - loss: 0.0542 - 4ms/epoch - 4ms/step\n",
      "Epoch 225/600\n",
      "1/1 - 0s - loss: 0.0538 - 3ms/epoch - 3ms/step\n",
      "Epoch 226/600\n",
      "1/1 - 0s - loss: 0.0539 - 3ms/epoch - 3ms/step\n",
      "Epoch 227/600\n",
      "1/1 - 0s - loss: 0.0538 - 3ms/epoch - 3ms/step\n",
      "Epoch 228/600\n",
      "1/1 - 0s - loss: 0.0538 - 3ms/epoch - 3ms/step\n",
      "Epoch 229/600\n",
      "1/1 - 0s - loss: 0.0537 - 4ms/epoch - 4ms/step\n",
      "Epoch 230/600\n",
      "1/1 - 0s - loss: 0.0536 - 3ms/epoch - 3ms/step\n",
      "Epoch 231/600\n",
      "1/1 - 0s - loss: 0.0538 - 3ms/epoch - 3ms/step\n",
      "Epoch 232/600\n",
      "1/1 - 0s - loss: 0.0537 - 3ms/epoch - 3ms/step\n",
      "Epoch 233/600\n",
      "1/1 - 0s - loss: 0.0535 - 4ms/epoch - 4ms/step\n",
      "Epoch 234/600\n",
      "1/1 - 0s - loss: 0.0534 - 4ms/epoch - 4ms/step\n",
      "Epoch 235/600\n",
      "1/1 - 0s - loss: 0.0537 - 3ms/epoch - 3ms/step\n",
      "Epoch 236/600\n",
      "1/1 - 0s - loss: 0.0534 - 4ms/epoch - 4ms/step\n",
      "Epoch 237/600\n",
      "1/1 - 0s - loss: 0.0535 - 3ms/epoch - 3ms/step\n",
      "Epoch 238/600\n",
      "1/1 - 0s - loss: 0.0536 - 3ms/epoch - 3ms/step\n",
      "Epoch 239/600\n",
      "1/1 - 0s - loss: 0.0535 - 4ms/epoch - 4ms/step\n",
      "Epoch 240/600\n",
      "1/1 - 0s - loss: 0.0534 - 4ms/epoch - 4ms/step\n",
      "Epoch 241/600\n",
      "1/1 - 0s - loss: 0.0533 - 3ms/epoch - 3ms/step\n",
      "Epoch 242/600\n",
      "1/1 - 0s - loss: 0.0533 - 3ms/epoch - 3ms/step\n",
      "Epoch 243/600\n",
      "1/1 - 0s - loss: 0.0532 - 4ms/epoch - 4ms/step\n",
      "Epoch 244/600\n",
      "1/1 - 0s - loss: 0.0534 - 4ms/epoch - 4ms/step\n",
      "Epoch 245/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 246/600\n",
      "1/1 - 0s - loss: 0.0531 - 5ms/epoch - 5ms/step\n",
      "Epoch 247/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 248/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 249/600\n",
      "1/1 - 0s - loss: 0.0531 - 5ms/epoch - 5ms/step\n",
      "Epoch 250/600\n",
      "1/1 - 0s - loss: 0.0532 - 3ms/epoch - 3ms/step\n",
      "Epoch 251/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 252/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 253/600\n",
      "1/1 - 0s - loss: 0.0531 - 3ms/epoch - 3ms/step\n",
      "Epoch 254/600\n",
      "1/1 - 0s - loss: 0.0531 - 9ms/epoch - 9ms/step\n",
      "Epoch 255/600\n",
      "1/1 - 0s - loss: 0.0530 - 5ms/epoch - 5ms/step\n",
      "Epoch 256/600\n",
      "1/1 - 0s - loss: 0.0530 - 5ms/epoch - 5ms/step\n",
      "Epoch 257/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 258/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 259/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 260/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 261/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 262/600\n",
      "1/1 - 0s - loss: 0.0531 - 3ms/epoch - 3ms/step\n",
      "Epoch 263/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 264/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 265/600\n",
      "1/1 - 0s - loss: 0.0529 - 3ms/epoch - 3ms/step\n",
      "Epoch 266/600\n",
      "1/1 - 0s - loss: 0.0530 - 4ms/epoch - 4ms/step\n",
      "Epoch 267/600\n",
      "1/1 - 0s - loss: 0.0526 - 4ms/epoch - 4ms/step\n",
      "Epoch 268/600\n",
      "1/1 - 0s - loss: 0.0531 - 4ms/epoch - 4ms/step\n",
      "Epoch 269/600\n",
      "1/1 - 0s - loss: 0.0532 - 4ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 271/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 272/600\n",
      "1/1 - 0s - loss: 0.0529 - 4ms/epoch - 4ms/step\n",
      "Epoch 273/600\n",
      "1/1 - 0s - loss: 0.0532 - 5ms/epoch - 5ms/step\n",
      "Epoch 274/600\n",
      "1/1 - 0s - loss: 0.0525 - 4ms/epoch - 4ms/step\n",
      "Epoch 275/600\n",
      "1/1 - 0s - loss: 0.0534 - 3ms/epoch - 3ms/step\n",
      "Epoch 276/600\n",
      "1/1 - 0s - loss: 0.0525 - 4ms/epoch - 4ms/step\n",
      "Epoch 277/600\n",
      "1/1 - 0s - loss: 0.0528 - 4ms/epoch - 4ms/step\n",
      "Epoch 278/600\n",
      "1/1 - 0s - loss: 0.0529 - 4ms/epoch - 4ms/step\n",
      "Epoch 279/600\n",
      "1/1 - 0s - loss: 0.0525 - 4ms/epoch - 4ms/step\n",
      "Epoch 280/600\n",
      "1/1 - 0s - loss: 0.0538 - 4ms/epoch - 4ms/step\n",
      "Epoch 281/600\n",
      "1/1 - 0s - loss: 0.0529 - 3ms/epoch - 3ms/step\n",
      "Epoch 282/600\n",
      "1/1 - 0s - loss: 0.0527 - 3ms/epoch - 3ms/step\n",
      "Epoch 283/600\n",
      "1/1 - 0s - loss: 0.0534 - 3ms/epoch - 3ms/step\n",
      "Epoch 284/600\n",
      "1/1 - 0s - loss: 0.0524 - 3ms/epoch - 3ms/step\n",
      "Epoch 285/600\n",
      "1/1 - 0s - loss: 0.0529 - 3ms/epoch - 3ms/step\n",
      "Epoch 286/600\n",
      "1/1 - 0s - loss: 0.0530 - 4ms/epoch - 4ms/step\n",
      "Epoch 287/600\n",
      "1/1 - 0s - loss: 0.0522 - 3ms/epoch - 3ms/step\n",
      "Epoch 288/600\n",
      "1/1 - 0s - loss: 0.0531 - 3ms/epoch - 3ms/step\n",
      "Epoch 289/600\n",
      "1/1 - 0s - loss: 0.0526 - 4ms/epoch - 4ms/step\n",
      "Epoch 290/600\n",
      "1/1 - 0s - loss: 0.0522 - 4ms/epoch - 4ms/step\n",
      "Epoch 291/600\n",
      "1/1 - 0s - loss: 0.0528 - 3ms/epoch - 3ms/step\n",
      "Epoch 292/600\n",
      "1/1 - 0s - loss: 0.0521 - 3ms/epoch - 3ms/step\n",
      "Epoch 293/600\n",
      "1/1 - 0s - loss: 0.0526 - 3ms/epoch - 3ms/step\n",
      "Epoch 294/600\n",
      "1/1 - 0s - loss: 0.0523 - 4ms/epoch - 4ms/step\n",
      "Epoch 295/600\n",
      "1/1 - 0s - loss: 0.0521 - 3ms/epoch - 3ms/step\n",
      "Epoch 296/600\n",
      "1/1 - 0s - loss: 0.0527 - 5ms/epoch - 5ms/step\n",
      "Epoch 297/600\n",
      "1/1 - 0s - loss: 0.0520 - 4ms/epoch - 4ms/step\n",
      "Epoch 298/600\n",
      "1/1 - 0s - loss: 0.0522 - 3ms/epoch - 3ms/step\n",
      "Epoch 299/600\n",
      "1/1 - 0s - loss: 0.0522 - 3ms/epoch - 3ms/step\n",
      "Epoch 300/600\n",
      "1/1 - 0s - loss: 0.0519 - 4ms/epoch - 4ms/step\n",
      "Epoch 301/600\n",
      "1/1 - 0s - loss: 0.0523 - 3ms/epoch - 3ms/step\n",
      "Epoch 302/600\n",
      "1/1 - 0s - loss: 0.0519 - 3ms/epoch - 3ms/step\n",
      "Epoch 303/600\n",
      "1/1 - 0s - loss: 0.0519 - 4ms/epoch - 4ms/step\n",
      "Epoch 304/600\n",
      "1/1 - 0s - loss: 0.0520 - 3ms/epoch - 3ms/step\n",
      "Epoch 305/600\n",
      "1/1 - 0s - loss: 0.0518 - 3ms/epoch - 3ms/step\n",
      "Epoch 306/600\n",
      "1/1 - 0s - loss: 0.0519 - 3ms/epoch - 3ms/step\n",
      "Epoch 307/600\n",
      "1/1 - 0s - loss: 0.0517 - 3ms/epoch - 3ms/step\n",
      "Epoch 308/600\n",
      "1/1 - 0s - loss: 0.0517 - 3ms/epoch - 3ms/step\n",
      "Epoch 309/600\n",
      "1/1 - 0s - loss: 0.0516 - 3ms/epoch - 3ms/step\n",
      "Epoch 310/600\n",
      "1/1 - 0s - loss: 0.0516 - 3ms/epoch - 3ms/step\n",
      "Epoch 311/600\n",
      "1/1 - 0s - loss: 0.0516 - 4ms/epoch - 4ms/step\n",
      "Epoch 312/600\n",
      "1/1 - 0s - loss: 0.0516 - 3ms/epoch - 3ms/step\n",
      "Epoch 313/600\n",
      "1/1 - 0s - loss: 0.0516 - 4ms/epoch - 4ms/step\n",
      "Epoch 314/600\n",
      "1/1 - 0s - loss: 0.0515 - 4ms/epoch - 4ms/step\n",
      "Epoch 315/600\n",
      "1/1 - 0s - loss: 0.0516 - 3ms/epoch - 3ms/step\n",
      "Epoch 316/600\n",
      "1/1 - 0s - loss: 0.0514 - 3ms/epoch - 3ms/step\n",
      "Epoch 317/600\n",
      "1/1 - 0s - loss: 0.0514 - 3ms/epoch - 3ms/step\n",
      "Epoch 318/600\n",
      "1/1 - 0s - loss: 0.0514 - 3ms/epoch - 3ms/step\n",
      "Epoch 319/600\n",
      "1/1 - 0s - loss: 0.0514 - 3ms/epoch - 3ms/step\n",
      "Epoch 320/600\n",
      "1/1 - 0s - loss: 0.0514 - 4ms/epoch - 4ms/step\n",
      "Epoch 321/600\n",
      "1/1 - 0s - loss: 0.0514 - 4ms/epoch - 4ms/step\n",
      "Epoch 322/600\n",
      "1/1 - 0s - loss: 0.0513 - 3ms/epoch - 3ms/step\n",
      "Epoch 323/600\n",
      "1/1 - 0s - loss: 0.0512 - 3ms/epoch - 3ms/step\n",
      "Epoch 324/600\n",
      "1/1 - 0s - loss: 0.0514 - 4ms/epoch - 4ms/step\n",
      "Epoch 325/600\n",
      "1/1 - 0s - loss: 0.0512 - 3ms/epoch - 3ms/step\n",
      "Epoch 326/600\n",
      "1/1 - 0s - loss: 0.0512 - 3ms/epoch - 3ms/step\n",
      "Epoch 327/600\n",
      "1/1 - 0s - loss: 0.0512 - 3ms/epoch - 3ms/step\n",
      "Epoch 328/600\n",
      "1/1 - 0s - loss: 0.0512 - 4ms/epoch - 4ms/step\n",
      "Epoch 329/600\n",
      "1/1 - 0s - loss: 0.0512 - 4ms/epoch - 4ms/step\n",
      "Epoch 330/600\n",
      "1/1 - 0s - loss: 0.0512 - 3ms/epoch - 3ms/step\n",
      "Epoch 331/600\n",
      "1/1 - 0s - loss: 0.0510 - 3ms/epoch - 3ms/step\n",
      "Epoch 332/600\n",
      "1/1 - 0s - loss: 0.0510 - 3ms/epoch - 3ms/step\n",
      "Epoch 333/600\n",
      "1/1 - 0s - loss: 0.0509 - 3ms/epoch - 3ms/step\n",
      "Epoch 334/600\n",
      "1/1 - 0s - loss: 0.0510 - 3ms/epoch - 3ms/step\n",
      "Epoch 335/600\n",
      "1/1 - 0s - loss: 0.0510 - 4ms/epoch - 4ms/step\n",
      "Epoch 336/600\n",
      "1/1 - 0s - loss: 0.0509 - 3ms/epoch - 3ms/step\n",
      "Epoch 337/600\n",
      "1/1 - 0s - loss: 0.0510 - 4ms/epoch - 4ms/step\n",
      "Epoch 338/600\n",
      "1/1 - 0s - loss: 0.0510 - 3ms/epoch - 3ms/step\n",
      "Epoch 339/600\n",
      "1/1 - 0s - loss: 0.0509 - 4ms/epoch - 4ms/step\n",
      "Epoch 340/600\n",
      "1/1 - 0s - loss: 0.0511 - 3ms/epoch - 3ms/step\n",
      "Epoch 341/600\n",
      "1/1 - 0s - loss: 0.0510 - 4ms/epoch - 4ms/step\n",
      "Epoch 342/600\n",
      "1/1 - 0s - loss: 0.0510 - 3ms/epoch - 3ms/step\n",
      "Epoch 343/600\n",
      "1/1 - 0s - loss: 0.0508 - 2ms/epoch - 2ms/step\n",
      "Epoch 344/600\n",
      "1/1 - 0s - loss: 0.0506 - 3ms/epoch - 3ms/step\n",
      "Epoch 345/600\n",
      "1/1 - 0s - loss: 0.0508 - 3ms/epoch - 3ms/step\n",
      "Epoch 346/600\n",
      "1/1 - 0s - loss: 0.0507 - 3ms/epoch - 3ms/step\n",
      "Epoch 347/600\n",
      "1/1 - 0s - loss: 0.0506 - 3ms/epoch - 3ms/step\n",
      "Epoch 348/600\n",
      "1/1 - 0s - loss: 0.0505 - 4ms/epoch - 4ms/step\n",
      "Epoch 349/600\n",
      "1/1 - 0s - loss: 0.0506 - 4ms/epoch - 4ms/step\n",
      "Epoch 350/600\n",
      "1/1 - 0s - loss: 0.0505 - 3ms/epoch - 3ms/step\n",
      "Epoch 351/600\n",
      "1/1 - 0s - loss: 0.0504 - 3ms/epoch - 3ms/step\n",
      "Epoch 352/600\n",
      "1/1 - 0s - loss: 0.0506 - 4ms/epoch - 4ms/step\n",
      "Epoch 353/600\n",
      "1/1 - 0s - loss: 0.0505 - 3ms/epoch - 3ms/step\n",
      "Epoch 354/600\n",
      "1/1 - 0s - loss: 0.0506 - 4ms/epoch - 4ms/step\n",
      "Epoch 355/600\n",
      "1/1 - 0s - loss: 0.0505 - 4ms/epoch - 4ms/step\n",
      "Epoch 356/600\n",
      "1/1 - 0s - loss: 0.0504 - 4ms/epoch - 4ms/step\n",
      "Epoch 357/600\n",
      "1/1 - 0s - loss: 0.0504 - 3ms/epoch - 3ms/step\n",
      "Epoch 358/600\n",
      "1/1 - 0s - loss: 0.0503 - 4ms/epoch - 4ms/step\n",
      "Epoch 359/600\n",
      "1/1 - 0s - loss: 0.0502 - 4ms/epoch - 4ms/step\n",
      "Epoch 360/600\n",
      "1/1 - 0s - loss: 0.0504 - 3ms/epoch - 3ms/step\n",
      "Epoch 361/600\n",
      "1/1 - 0s - loss: 0.0502 - 4ms/epoch - 4ms/step\n",
      "Epoch 362/600\n",
      "1/1 - 0s - loss: 0.0503 - 4ms/epoch - 4ms/step\n",
      "Epoch 363/600\n",
      "1/1 - 0s - loss: 0.0509 - 3ms/epoch - 3ms/step\n",
      "Epoch 364/600\n",
      "1/1 - 0s - loss: 0.0506 - 3ms/epoch - 3ms/step\n",
      "Epoch 365/600\n",
      "1/1 - 0s - loss: 0.0508 - 3ms/epoch - 3ms/step\n",
      "Epoch 366/600\n",
      "1/1 - 0s - loss: 0.0500 - 4ms/epoch - 4ms/step\n",
      "Epoch 367/600\n",
      "1/1 - 0s - loss: 0.0501 - 3ms/epoch - 3ms/step\n",
      "Epoch 368/600\n",
      "1/1 - 0s - loss: 0.0501 - 4ms/epoch - 4ms/step\n",
      "Epoch 369/600\n",
      "1/1 - 0s - loss: 0.0500 - 3ms/epoch - 3ms/step\n",
      "Epoch 370/600\n",
      "1/1 - 0s - loss: 0.0501 - 4ms/epoch - 4ms/step\n",
      "Epoch 371/600\n",
      "1/1 - 0s - loss: 0.0502 - 3ms/epoch - 3ms/step\n",
      "Epoch 372/600\n",
      "1/1 - 0s - loss: 0.0499 - 3ms/epoch - 3ms/step\n",
      "Epoch 373/600\n",
      "1/1 - 0s - loss: 0.0501 - 3ms/epoch - 3ms/step\n",
      "Epoch 374/600\n",
      "1/1 - 0s - loss: 0.0500 - 3ms/epoch - 3ms/step\n",
      "Epoch 375/600\n",
      "1/1 - 0s - loss: 0.0499 - 4ms/epoch - 4ms/step\n",
      "Epoch 376/600\n",
      "1/1 - 0s - loss: 0.0501 - 4ms/epoch - 4ms/step\n",
      "Epoch 377/600\n",
      "1/1 - 0s - loss: 0.0497 - 3ms/epoch - 3ms/step\n",
      "Epoch 378/600\n",
      "1/1 - 0s - loss: 0.0510 - 3ms/epoch - 3ms/step\n",
      "Epoch 379/600\n",
      "1/1 - 0s - loss: 0.0497 - 3ms/epoch - 3ms/step\n",
      "Epoch 380/600\n",
      "1/1 - 0s - loss: 0.0500 - 3ms/epoch - 3ms/step\n",
      "Epoch 381/600\n",
      "1/1 - 0s - loss: 0.0499 - 3ms/epoch - 3ms/step\n",
      "Epoch 382/600\n",
      "1/1 - 0s - loss: 0.0496 - 3ms/epoch - 3ms/step\n",
      "Epoch 383/600\n",
      "1/1 - 0s - loss: 0.0499 - 3ms/epoch - 3ms/step\n",
      "Epoch 384/600\n",
      "1/1 - 0s - loss: 0.0498 - 3ms/epoch - 3ms/step\n",
      "Epoch 385/600\n",
      "1/1 - 0s - loss: 0.0496 - 4ms/epoch - 4ms/step\n",
      "Epoch 386/600\n",
      "1/1 - 0s - loss: 0.0501 - 3ms/epoch - 3ms/step\n",
      "Epoch 387/600\n",
      "1/1 - 0s - loss: 0.0496 - 4ms/epoch - 4ms/step\n",
      "Epoch 388/600\n",
      "1/1 - 0s - loss: 0.0506 - 4ms/epoch - 4ms/step\n",
      "Epoch 389/600\n",
      "1/1 - 0s - loss: 0.0494 - 4ms/epoch - 4ms/step\n",
      "Epoch 390/600\n",
      "1/1 - 0s - loss: 0.0507 - 4ms/epoch - 4ms/step\n",
      "Epoch 391/600\n",
      "1/1 - 0s - loss: 0.0502 - 4ms/epoch - 4ms/step\n",
      "Epoch 392/600\n",
      "1/1 - 0s - loss: 0.0501 - 4ms/epoch - 4ms/step\n",
      "Epoch 393/600\n",
      "1/1 - 0s - loss: 0.0494 - 4ms/epoch - 4ms/step\n",
      "Epoch 394/600\n",
      "1/1 - 0s - loss: 0.0501 - 3ms/epoch - 3ms/step\n",
      "Epoch 395/600\n",
      "1/1 - 0s - loss: 0.0497 - 4ms/epoch - 4ms/step\n",
      "Epoch 396/600\n",
      "1/1 - 0s - loss: 0.0505 - 4ms/epoch - 4ms/step\n",
      "Epoch 397/600\n",
      "1/1 - 0s - loss: 0.0496 - 3ms/epoch - 3ms/step\n",
      "Epoch 398/600\n",
      "1/1 - 0s - loss: 0.0504 - 4ms/epoch - 4ms/step\n",
      "Epoch 399/600\n",
      "1/1 - 0s - loss: 0.0506 - 3ms/epoch - 3ms/step\n",
      "Epoch 400/600\n",
      "1/1 - 0s - loss: 0.0495 - 4ms/epoch - 4ms/step\n",
      "Epoch 401/600\n",
      "1/1 - 0s - loss: 0.0505 - 3ms/epoch - 3ms/step\n",
      "Epoch 402/600\n",
      "1/1 - 0s - loss: 0.0493 - 3ms/epoch - 3ms/step\n",
      "Epoch 403/600\n",
      "1/1 - 0s - loss: 0.0499 - 4ms/epoch - 4ms/step\n",
      "Epoch 404/600\n",
      "1/1 - 0s - loss: 0.0495 - 4ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/600\n",
      "1/1 - 0s - loss: 0.0501 - 4ms/epoch - 4ms/step\n",
      "Epoch 406/600\n",
      "1/1 - 0s - loss: 0.0492 - 4ms/epoch - 4ms/step\n",
      "Epoch 407/600\n",
      "1/1 - 0s - loss: 0.0505 - 4ms/epoch - 4ms/step\n",
      "Epoch 408/600\n",
      "1/1 - 0s - loss: 0.0503 - 4ms/epoch - 4ms/step\n",
      "Epoch 409/600\n",
      "1/1 - 0s - loss: 0.0493 - 4ms/epoch - 4ms/step\n",
      "Epoch 410/600\n",
      "1/1 - 0s - loss: 0.0501 - 3ms/epoch - 3ms/step\n",
      "Epoch 411/600\n",
      "1/1 - 0s - loss: 0.0496 - 4ms/epoch - 4ms/step\n",
      "Epoch 412/600\n",
      "1/1 - 0s - loss: 0.0502 - 4ms/epoch - 4ms/step\n",
      "Epoch 413/600\n",
      "1/1 - 0s - loss: 0.0491 - 3ms/epoch - 3ms/step\n",
      "Epoch 414/600\n",
      "1/1 - 0s - loss: 0.0501 - 3ms/epoch - 3ms/step\n",
      "Epoch 415/600\n",
      "1/1 - 0s - loss: 0.0490 - 4ms/epoch - 4ms/step\n",
      "Epoch 416/600\n",
      "1/1 - 0s - loss: 0.0497 - 4ms/epoch - 4ms/step\n",
      "Epoch 417/600\n",
      "1/1 - 0s - loss: 0.0493 - 3ms/epoch - 3ms/step\n",
      "Epoch 418/600\n",
      "1/1 - 0s - loss: 0.0497 - 4ms/epoch - 4ms/step\n",
      "Epoch 419/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 420/600\n",
      "1/1 - 0s - loss: 0.0497 - 3ms/epoch - 3ms/step\n",
      "Epoch 421/600\n",
      "1/1 - 0s - loss: 0.0491 - 4ms/epoch - 4ms/step\n",
      "Epoch 422/600\n",
      "1/1 - 0s - loss: 0.0497 - 4ms/epoch - 4ms/step\n",
      "Epoch 423/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 424/600\n",
      "1/1 - 0s - loss: 0.0493 - 4ms/epoch - 4ms/step\n",
      "Epoch 425/600\n",
      "1/1 - 0s - loss: 0.0490 - 4ms/epoch - 4ms/step\n",
      "Epoch 426/600\n",
      "1/1 - 0s - loss: 0.0492 - 3ms/epoch - 3ms/step\n",
      "Epoch 427/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 428/600\n",
      "1/1 - 0s - loss: 0.0488 - 4ms/epoch - 4ms/step\n",
      "Epoch 429/600\n",
      "1/1 - 0s - loss: 0.0489 - 4ms/epoch - 4ms/step\n",
      "Epoch 430/600\n",
      "1/1 - 0s - loss: 0.0487 - 4ms/epoch - 4ms/step\n",
      "Epoch 431/600\n",
      "1/1 - 0s - loss: 0.0487 - 3ms/epoch - 3ms/step\n",
      "Epoch 432/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 433/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 434/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 435/600\n",
      "1/1 - 0s - loss: 0.0492 - 3ms/epoch - 3ms/step\n",
      "Epoch 436/600\n",
      "1/1 - 0s - loss: 0.0486 - 4ms/epoch - 4ms/step\n",
      "Epoch 437/600\n",
      "1/1 - 0s - loss: 0.0488 - 4ms/epoch - 4ms/step\n",
      "Epoch 438/600\n",
      "1/1 - 0s - loss: 0.0487 - 3ms/epoch - 3ms/step\n",
      "Epoch 439/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 440/600\n",
      "1/1 - 0s - loss: 0.0486 - 3ms/epoch - 3ms/step\n",
      "Epoch 441/600\n",
      "1/1 - 0s - loss: 0.0493 - 4ms/epoch - 4ms/step\n",
      "Epoch 442/600\n",
      "1/1 - 0s - loss: 0.0485 - 4ms/epoch - 4ms/step\n",
      "Epoch 443/600\n",
      "1/1 - 0s - loss: 0.0487 - 4ms/epoch - 4ms/step\n",
      "Epoch 444/600\n",
      "1/1 - 0s - loss: 0.0484 - 4ms/epoch - 4ms/step\n",
      "Epoch 445/600\n",
      "1/1 - 0s - loss: 0.0490 - 3ms/epoch - 3ms/step\n",
      "Epoch 446/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 447/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 448/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 449/600\n",
      "1/1 - 0s - loss: 0.0484 - 4ms/epoch - 4ms/step\n",
      "Epoch 450/600\n",
      "1/1 - 0s - loss: 0.0486 - 3ms/epoch - 3ms/step\n",
      "Epoch 451/600\n",
      "1/1 - 0s - loss: 0.0485 - 3ms/epoch - 3ms/step\n",
      "Epoch 452/600\n",
      "1/1 - 0s - loss: 0.0487 - 3ms/epoch - 3ms/step\n",
      "Epoch 453/600\n",
      "1/1 - 0s - loss: 0.0485 - 4ms/epoch - 4ms/step\n",
      "Epoch 454/600\n",
      "1/1 - 0s - loss: 0.0488 - 4ms/epoch - 4ms/step\n",
      "Epoch 455/600\n",
      "1/1 - 0s - loss: 0.0484 - 3ms/epoch - 3ms/step\n",
      "Epoch 456/600\n",
      "1/1 - 0s - loss: 0.0493 - 3ms/epoch - 3ms/step\n",
      "Epoch 457/600\n",
      "1/1 - 0s - loss: 0.0484 - 3ms/epoch - 3ms/step\n",
      "Epoch 458/600\n",
      "1/1 - 0s - loss: 0.0492 - 3ms/epoch - 3ms/step\n",
      "Epoch 459/600\n",
      "1/1 - 0s - loss: 0.0484 - 3ms/epoch - 3ms/step\n",
      "Epoch 460/600\n",
      "1/1 - 0s - loss: 0.0491 - 3ms/epoch - 3ms/step\n",
      "Epoch 461/600\n",
      "1/1 - 0s - loss: 0.0483 - 3ms/epoch - 3ms/step\n",
      "Epoch 462/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 463/600\n",
      "1/1 - 0s - loss: 0.0482 - 4ms/epoch - 4ms/step\n",
      "Epoch 464/600\n",
      "1/1 - 0s - loss: 0.0498 - 3ms/epoch - 3ms/step\n",
      "Epoch 465/600\n",
      "1/1 - 0s - loss: 0.0482 - 3ms/epoch - 3ms/step\n",
      "Epoch 466/600\n",
      "1/1 - 0s - loss: 0.0490 - 3ms/epoch - 3ms/step\n",
      "Epoch 467/600\n",
      "1/1 - 0s - loss: 0.0485 - 4ms/epoch - 4ms/step\n",
      "Epoch 468/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 469/600\n",
      "1/1 - 0s - loss: 0.0482 - 3ms/epoch - 3ms/step\n",
      "Epoch 470/600\n",
      "1/1 - 0s - loss: 0.0483 - 3ms/epoch - 3ms/step\n",
      "Epoch 471/600\n",
      "1/1 - 0s - loss: 0.0481 - 3ms/epoch - 3ms/step\n",
      "Epoch 472/600\n",
      "1/1 - 0s - loss: 0.0490 - 3ms/epoch - 3ms/step\n",
      "Epoch 473/600\n",
      "1/1 - 0s - loss: 0.0482 - 3ms/epoch - 3ms/step\n",
      "Epoch 474/600\n",
      "1/1 - 0s - loss: 0.0487 - 14ms/epoch - 14ms/step\n",
      "Epoch 475/600\n",
      "1/1 - 0s - loss: 0.0481 - 4ms/epoch - 4ms/step\n",
      "Epoch 476/600\n",
      "1/1 - 0s - loss: 0.0486 - 3ms/epoch - 3ms/step\n",
      "Epoch 477/600\n",
      "1/1 - 0s - loss: 0.0484 - 3ms/epoch - 3ms/step\n",
      "Epoch 478/600\n",
      "1/1 - 0s - loss: 0.0486 - 4ms/epoch - 4ms/step\n",
      "Epoch 479/600\n",
      "1/1 - 0s - loss: 0.0482 - 3ms/epoch - 3ms/step\n",
      "Epoch 480/600\n",
      "1/1 - 0s - loss: 0.0480 - 3ms/epoch - 3ms/step\n",
      "Epoch 481/600\n",
      "1/1 - 0s - loss: 0.0481 - 3ms/epoch - 3ms/step\n",
      "Epoch 482/600\n",
      "1/1 - 0s - loss: 0.0483 - 3ms/epoch - 3ms/step\n",
      "Epoch 483/600\n",
      "1/1 - 0s - loss: 0.0479 - 4ms/epoch - 4ms/step\n",
      "Epoch 484/600\n",
      "1/1 - 0s - loss: 0.0488 - 3ms/epoch - 3ms/step\n",
      "Epoch 485/600\n",
      "1/1 - 0s - loss: 0.0482 - 3ms/epoch - 3ms/step\n",
      "Epoch 486/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 487/600\n",
      "1/1 - 0s - loss: 0.0480 - 4ms/epoch - 4ms/step\n",
      "Epoch 488/600\n",
      "1/1 - 0s - loss: 0.0493 - 4ms/epoch - 4ms/step\n",
      "Epoch 489/600\n",
      "1/1 - 0s - loss: 0.0479 - 3ms/epoch - 3ms/step\n",
      "Epoch 490/600\n",
      "1/1 - 0s - loss: 0.0484 - 3ms/epoch - 3ms/step\n",
      "Epoch 491/600\n",
      "1/1 - 0s - loss: 0.0481 - 3ms/epoch - 3ms/step\n",
      "Epoch 492/600\n",
      "1/1 - 0s - loss: 0.0478 - 4ms/epoch - 4ms/step\n",
      "Epoch 493/600\n",
      "1/1 - 0s - loss: 0.0489 - 3ms/epoch - 3ms/step\n",
      "Epoch 494/600\n",
      "1/1 - 0s - loss: 0.0478 - 3ms/epoch - 3ms/step\n",
      "Epoch 495/600\n",
      "1/1 - 0s - loss: 0.0481 - 4ms/epoch - 4ms/step\n",
      "Epoch 496/600\n",
      "1/1 - 0s - loss: 0.0478 - 3ms/epoch - 3ms/step\n",
      "Epoch 497/600\n",
      "1/1 - 0s - loss: 0.0480 - 3ms/epoch - 3ms/step\n",
      "Epoch 498/600\n",
      "1/1 - 0s - loss: 0.0478 - 3ms/epoch - 3ms/step\n",
      "Epoch 499/600\n",
      "1/1 - 0s - loss: 0.0480 - 3ms/epoch - 3ms/step\n",
      "Epoch 500/600\n",
      "1/1 - 0s - loss: 0.0477 - 3ms/epoch - 3ms/step\n",
      "Epoch 501/600\n",
      "1/1 - 0s - loss: 0.0484 - 3ms/epoch - 3ms/step\n",
      "Epoch 502/600\n",
      "1/1 - 0s - loss: 0.0478 - 3ms/epoch - 3ms/step\n",
      "Epoch 503/600\n",
      "1/1 - 0s - loss: 0.0481 - 3ms/epoch - 3ms/step\n",
      "Epoch 504/600\n",
      "1/1 - 0s - loss: 0.0479 - 4ms/epoch - 4ms/step\n",
      "Epoch 505/600\n",
      "1/1 - 0s - loss: 0.0476 - 4ms/epoch - 4ms/step\n",
      "Epoch 506/600\n",
      "1/1 - 0s - loss: 0.0477 - 3ms/epoch - 3ms/step\n",
      "Epoch 507/600\n",
      "1/1 - 0s - loss: 0.0478 - 3ms/epoch - 3ms/step\n",
      "Epoch 508/600\n",
      "1/1 - 0s - loss: 0.0476 - 3ms/epoch - 3ms/step\n",
      "Epoch 509/600\n",
      "1/1 - 0s - loss: 0.0478 - 3ms/epoch - 3ms/step\n",
      "Epoch 510/600\n",
      "1/1 - 0s - loss: 0.0477 - 3ms/epoch - 3ms/step\n",
      "Epoch 511/600\n",
      "1/1 - 0s - loss: 0.0478 - 4ms/epoch - 4ms/step\n",
      "Epoch 512/600\n",
      "1/1 - 0s - loss: 0.0478 - 4ms/epoch - 4ms/step\n",
      "Epoch 513/600\n",
      "1/1 - 0s - loss: 0.0475 - 4ms/epoch - 4ms/step\n",
      "Epoch 514/600\n",
      "1/1 - 0s - loss: 0.0476 - 3ms/epoch - 3ms/step\n",
      "Epoch 515/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 516/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 517/600\n",
      "1/1 - 0s - loss: 0.0474 - 3ms/epoch - 3ms/step\n",
      "Epoch 518/600\n",
      "1/1 - 0s - loss: 0.0476 - 3ms/epoch - 3ms/step\n",
      "Epoch 519/600\n",
      "1/1 - 0s - loss: 0.0474 - 4ms/epoch - 4ms/step\n",
      "Epoch 520/600\n",
      "1/1 - 0s - loss: 0.0476 - 3ms/epoch - 3ms/step\n",
      "Epoch 521/600\n",
      "1/1 - 0s - loss: 0.0474 - 3ms/epoch - 3ms/step\n",
      "Epoch 522/600\n",
      "1/1 - 0s - loss: 0.0475 - 4ms/epoch - 4ms/step\n",
      "Epoch 523/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 524/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 525/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 526/600\n",
      "1/1 - 0s - loss: 0.0473 - 4ms/epoch - 4ms/step\n",
      "Epoch 527/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 528/600\n",
      "1/1 - 0s - loss: 0.0474 - 3ms/epoch - 3ms/step\n",
      "Epoch 529/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 530/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 531/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 532/600\n",
      "1/1 - 0s - loss: 0.0475 - 4ms/epoch - 4ms/step\n",
      "Epoch 533/600\n",
      "1/1 - 0s - loss: 0.0473 - 4ms/epoch - 4ms/step\n",
      "Epoch 534/600\n",
      "1/1 - 0s - loss: 0.0472 - 3ms/epoch - 3ms/step\n",
      "Epoch 535/600\n",
      "1/1 - 0s - loss: 0.0474 - 3ms/epoch - 3ms/step\n",
      "Epoch 536/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 537/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 538/600\n",
      "1/1 - 0s - loss: 0.0478 - 4ms/epoch - 4ms/step\n",
      "Epoch 539/600\n",
      "1/1 - 0s - loss: 0.0471 - 3ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 541/600\n",
      "1/1 - 0s - loss: 0.0470 - 3ms/epoch - 3ms/step\n",
      "Epoch 542/600\n",
      "1/1 - 0s - loss: 0.0474 - 3ms/epoch - 3ms/step\n",
      "Epoch 543/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 544/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 545/600\n",
      "1/1 - 0s - loss: 0.0474 - 3ms/epoch - 3ms/step\n",
      "Epoch 546/600\n",
      "1/1 - 0s - loss: 0.0471 - 3ms/epoch - 3ms/step\n",
      "Epoch 547/600\n",
      "1/1 - 0s - loss: 0.0471 - 3ms/epoch - 3ms/step\n",
      "Epoch 548/600\n",
      "1/1 - 0s - loss: 0.0473 - 4ms/epoch - 4ms/step\n",
      "Epoch 549/600\n",
      "1/1 - 0s - loss: 0.0470 - 4ms/epoch - 4ms/step\n",
      "Epoch 550/600\n",
      "1/1 - 0s - loss: 0.0472 - 4ms/epoch - 4ms/step\n",
      "Epoch 551/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 552/600\n",
      "1/1 - 0s - loss: 0.0475 - 4ms/epoch - 4ms/step\n",
      "Epoch 553/600\n",
      "1/1 - 0s - loss: 0.0469 - 4ms/epoch - 4ms/step\n",
      "Epoch 554/600\n",
      "1/1 - 0s - loss: 0.0471 - 3ms/epoch - 3ms/step\n",
      "Epoch 555/600\n",
      "1/1 - 0s - loss: 0.0479 - 4ms/epoch - 4ms/step\n",
      "Epoch 556/600\n",
      "1/1 - 0s - loss: 0.0479 - 4ms/epoch - 4ms/step\n",
      "Epoch 557/600\n",
      "1/1 - 0s - loss: 0.0469 - 3ms/epoch - 3ms/step\n",
      "Epoch 558/600\n",
      "1/1 - 0s - loss: 0.0474 - 4ms/epoch - 4ms/step\n",
      "Epoch 559/600\n",
      "1/1 - 0s - loss: 0.0471 - 4ms/epoch - 4ms/step\n",
      "Epoch 560/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 561/600\n",
      "1/1 - 0s - loss: 0.0470 - 3ms/epoch - 3ms/step\n",
      "Epoch 562/600\n",
      "1/1 - 0s - loss: 0.0475 - 4ms/epoch - 4ms/step\n",
      "Epoch 563/600\n",
      "1/1 - 0s - loss: 0.0470 - 4ms/epoch - 4ms/step\n",
      "Epoch 564/600\n",
      "1/1 - 0s - loss: 0.0481 - 3ms/epoch - 3ms/step\n",
      "Epoch 565/600\n",
      "1/1 - 0s - loss: 0.0470 - 3ms/epoch - 3ms/step\n",
      "Epoch 566/600\n",
      "1/1 - 0s - loss: 0.0475 - 3ms/epoch - 3ms/step\n",
      "Epoch 567/600\n",
      "1/1 - 0s - loss: 0.0468 - 3ms/epoch - 3ms/step\n",
      "Epoch 568/600\n",
      "1/1 - 0s - loss: 0.0472 - 3ms/epoch - 3ms/step\n",
      "Epoch 569/600\n",
      "1/1 - 0s - loss: 0.0473 - 4ms/epoch - 4ms/step\n",
      "Epoch 570/600\n",
      "1/1 - 0s - loss: 0.0467 - 4ms/epoch - 4ms/step\n",
      "Epoch 571/600\n",
      "1/1 - 0s - loss: 0.0470 - 3ms/epoch - 3ms/step\n",
      "Epoch 572/600\n",
      "1/1 - 0s - loss: 0.0470 - 4ms/epoch - 4ms/step\n",
      "Epoch 573/600\n",
      "1/1 - 0s - loss: 0.0472 - 4ms/epoch - 4ms/step\n",
      "Epoch 574/600\n",
      "1/1 - 0s - loss: 0.0466 - 3ms/epoch - 3ms/step\n",
      "Epoch 575/600\n",
      "1/1 - 0s - loss: 0.0474 - 5ms/epoch - 5ms/step\n",
      "Epoch 576/600\n",
      "1/1 - 0s - loss: 0.0466 - 3ms/epoch - 3ms/step\n",
      "Epoch 577/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 578/600\n",
      "1/1 - 0s - loss: 0.0465 - 4ms/epoch - 4ms/step\n",
      "Epoch 579/600\n",
      "1/1 - 0s - loss: 0.0481 - 4ms/epoch - 4ms/step\n",
      "Epoch 580/600\n",
      "1/1 - 0s - loss: 0.0466 - 4ms/epoch - 4ms/step\n",
      "Epoch 581/600\n",
      "1/1 - 0s - loss: 0.0473 - 3ms/epoch - 3ms/step\n",
      "Epoch 582/600\n",
      "1/1 - 0s - loss: 0.0467 - 4ms/epoch - 4ms/step\n",
      "Epoch 583/600\n",
      "1/1 - 0s - loss: 0.0470 - 3ms/epoch - 3ms/step\n",
      "Epoch 584/600\n",
      "1/1 - 0s - loss: 0.0464 - 3ms/epoch - 3ms/step\n",
      "Epoch 585/600\n",
      "1/1 - 0s - loss: 0.0471 - 3ms/epoch - 3ms/step\n",
      "Epoch 586/600\n",
      "1/1 - 0s - loss: 0.0467 - 4ms/epoch - 4ms/step\n",
      "Epoch 587/600\n",
      "1/1 - 0s - loss: 0.0468 - 3ms/epoch - 3ms/step\n",
      "Epoch 588/600\n",
      "1/1 - 0s - loss: 0.0463 - 4ms/epoch - 4ms/step\n",
      "Epoch 589/600\n",
      "1/1 - 0s - loss: 0.0465 - 4ms/epoch - 4ms/step\n",
      "Epoch 590/600\n",
      "1/1 - 0s - loss: 0.0464 - 3ms/epoch - 3ms/step\n",
      "Epoch 591/600\n",
      "1/1 - 0s - loss: 0.0463 - 4ms/epoch - 4ms/step\n",
      "Epoch 592/600\n",
      "1/1 - 0s - loss: 0.0466 - 4ms/epoch - 4ms/step\n",
      "Epoch 593/600\n",
      "1/1 - 0s - loss: 0.0465 - 3ms/epoch - 3ms/step\n",
      "Epoch 594/600\n",
      "1/1 - 0s - loss: 0.0467 - 4ms/epoch - 4ms/step\n",
      "Epoch 595/600\n",
      "1/1 - 0s - loss: 0.0462 - 4ms/epoch - 4ms/step\n",
      "Epoch 596/600\n",
      "1/1 - 0s - loss: 0.0472 - 4ms/epoch - 4ms/step\n",
      "Epoch 597/600\n",
      "1/1 - 0s - loss: 0.0463 - 3ms/epoch - 3ms/step\n",
      "Epoch 598/600\n",
      "1/1 - 0s - loss: 0.0469 - 3ms/epoch - 3ms/step\n",
      "Epoch 599/600\n",
      "1/1 - 0s - loss: 0.0462 - 4ms/epoch - 4ms/step\n",
      "Epoch 600/600\n",
      "1/1 - 0s - loss: 0.0471 - 4ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 9.218\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# load dataset\n",
    "dataset = df\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "#values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# specify the number of lag hours\n",
    "n_hours = 3\n",
    "n_features = 6\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 50\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(test_y)\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=600, batch_size=72, verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -6:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -6:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd7049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
